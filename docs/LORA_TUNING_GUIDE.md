# LoRA 调参指南

## 当前配置

当前 v2_lora 使用的 LoRA 配置：

```yaml
lora_config:
  r: 16                    # LoRA rank
  lora_alpha: 32          # LoRA alpha（通常设置为 r 的 2 倍）
  target_modules: ['q_proj', 'v_proj', 'k_proj', 'out_proj']  # 目标模块
  lora_dropout: 0.1       # LoRA dropout
  bias: 'none'            # bias 处理方式
```

**当前性能**：
- v2_lora 与 v2 性能基本一致（差异 ±0.13%）
- 可训练参数：约 3M（Text: 786K, Vision: 1.18M）
- 训练效率：比 v2 更快（参数更少）

## 可调整参数及其影响

### 1. `r` (LoRA Rank) - **最重要参数**

**作用**：控制 LoRA 矩阵的秩，决定 LoRA 的容量和表达能力。

**当前值**：16

**可调范围**：8, 16, 32, 64, 128

**影响**：
- **r 增大**：
  - ✅ 模型容量增加，可能提升性能
  - ✅ 更强的任务适应能力
  - ❌ 可训练参数增加（参数数量 ≈ r × 2 × 模块数）
  - ❌ 训练时间增加
  - ❌ 可能过拟合（特别是数据量小时）

- **r 减小**：
  - ✅ 可训练参数减少，训练更快
  - ✅ 更不容易过拟合
  - ❌ 模型容量降低，可能限制性能
  - ❌ 任务适应能力减弱

**调参建议**：
- **保守提升**：尝试 `r=32`（参数增加约 2 倍，可能提升 0.2-0.5%）
- **激进提升**：尝试 `r=64`（参数增加约 4 倍，可能提升 0.5-1.0%，但需注意过拟合）
- **快速实验**：尝试 `r=8`（验证是否可以用更少参数达到相同效果）

**参数数量估算**：
- r=16: ~3M 参数
- r=32: ~6M 参数
- r=64: ~12M 参数

### 2. `lora_alpha` (LoRA Alpha)

**作用**：控制 LoRA 权重的缩放因子，影响 LoRA 对原始权重的贡献。

**当前值**：32（r 的 2 倍）

**可调范围**：通常设置为 r 的 1-4 倍（8, 16, 32, 64, 128）

**影响**：
- **alpha 增大**：
  - ✅ LoRA 权重影响更大
  - ✅ 可能提升性能（如果 r 足够大）
  - ❌ 可能不稳定（如果 alpha 过大）

- **alpha 减小**：
  - ✅ 更保守的更新
  - ✅ 训练更稳定
  - ❌ 可能性能提升有限

**调参建议**：
- **标准设置**：`alpha = 2 × r`（当前设置）
- **增强影响**：尝试 `alpha = 4 × r`（如 r=16, alpha=64）
- **保守设置**：尝试 `alpha = r`（如 r=16, alpha=16）

**经验公式**：
- 缩放因子 = alpha / r
- 当前：32/16 = 2.0（标准）
- 增强：64/16 = 4.0（更强影响）
- 保守：16/16 = 1.0（更弱影响）

### 3. `target_modules` (目标模块)

**作用**：决定在哪些模块上应用 LoRA。

**当前值**：`['q_proj', 'v_proj', 'k_proj', 'out_proj']`（注意力层的所有投影）

**可选值**：
- **注意力层**：`['q_proj', 'v_proj', 'k_proj', 'out_proj']`（当前）
- **MLP 层**：`['fc1', 'fc2']` 或 `['mlp.fc1', 'mlp.fc2']`
- **所有层**：`['q_proj', 'v_proj', 'k_proj', 'out_proj', 'fc1', 'fc2']`
- **特定层**：根据 CLIP 架构选择

**影响**：
- **增加模块**：
  - ✅ 更多参数可训练，可能提升性能
  - ✅ 更全面的任务适应
  - ❌ 可训练参数增加
  - ❌ 训练时间增加

- **减少模块**：
  - ✅ 参数更少，训练更快
  - ❌ 可能限制性能提升

**调参建议**：
- **当前设置**：只训练注意力层（标准做法）
- **增强设置**：添加 MLP 层 `['q_proj', 'v_proj', 'k_proj', 'out_proj', 'fc1', 'fc2']`
- **注意**：需要检查 CLIP 模型的实际模块名称

### 4. `lora_dropout` (LoRA Dropout)

**作用**：在 LoRA 层应用 dropout，防止过拟合。

**当前值**：0.1

**可调范围**：0.0, 0.05, 0.1, 0.2, 0.3

**影响**：
- **dropout 增大**：
  - ✅ 更强的正则化，减少过拟合
  - ✅ 可能提升泛化能力
  - ❌ 可能限制模型容量
  - ❌ 训练可能更慢

- **dropout 减小**：
  - ✅ 模型容量更大
  - ✅ 训练更快
  - ❌ 可能过拟合（特别是数据量小时）

**调参建议**：
- **当前设置**：0.1（标准）
- **数据量大**：尝试 0.0 或 0.05（减少正则化）
- **数据量小**：尝试 0.2（增强正则化）
- **过拟合时**：尝试 0.2-0.3

### 5. `bias` (Bias 处理)

**作用**：决定是否训练 bias 参数。

**当前值**：`'none'`（不训练 bias）

**可选值**：
- `'none'`：不训练 bias（当前）
- `'all'`：训练所有 bias
- `'lora_only'`：只训练 LoRA 相关的 bias

**影响**：
- **训练 bias**：
  - ✅ 可能提升性能（特别是任务特定偏移）
  - ❌ 参数增加（但通常很少）
  - ❌ 可能过拟合

- **不训练 bias**：
  - ✅ 参数更少
  - ✅ 更不容易过拟合
  - ❌ 可能限制性能

**调参建议**：
- **当前设置**：`'none'`（标准，参数最少）
- **性能优先**：尝试 `'lora_only'`（只增加少量参数）
- **极致性能**：尝试 `'all'`（但需注意过拟合）

## 调参实验建议

### 方案 1：保守提升（推荐先试）

**目标**：在保持训练效率的同时，小幅提升性能（预期 +0.2-0.5%）

```yaml
lora_config:
  r: 32                    # 从 16 增加到 32
  lora_alpha: 64          # 保持 alpha = 2 × r
  target_modules: ['q_proj', 'v_proj', 'k_proj', 'out_proj']
  lora_dropout: 0.1
  bias: 'none'
```

**预期**：
- 参数：~6M（增加 2 倍）
- 性能：可能提升 0.2-0.5%
- 训练时间：增加约 2 倍

### 方案 2：平衡提升

**目标**：在性能和效率之间取得平衡（预期 +0.5-1.0%）

```yaml
lora_config:
  r: 32
  lora_alpha: 128         # alpha = 4 × r（增强影响）
  target_modules: ['q_proj', 'v_proj', 'k_proj', 'out_proj']
  lora_dropout: 0.1
  bias: 'lora_only'       # 训练 LoRA bias
```

**预期**：
- 参数：~6.5M
- 性能：可能提升 0.5-1.0%
- 训练时间：增加约 2.5 倍

### 方案 3：激进提升

**目标**：追求极致性能（预期 +1.0-2.0%，但需注意过拟合）

```yaml
lora_config:
  r: 64                    # 大幅增加 rank
  lora_alpha: 128         # alpha = 2 × r
  target_modules: ['q_proj', 'v_proj', 'k_proj', 'out_proj', 'fc1', 'fc2']  # 添加 MLP
  lora_dropout: 0.05      # 减少 dropout
  bias: 'lora_only'
```

**预期**：
- 参数：~15-20M（取决于是否添加 MLP）
- 性能：可能提升 1.0-2.0%
- 训练时间：增加约 5-7 倍
- **风险**：可能过拟合，需要更多数据或更强的正则化

### 方案 4：效率优化

**目标**：用更少参数达到相同或更好性能

```yaml
lora_config:
  r: 8                     # 减小 rank
  lora_alpha: 16          # alpha = 2 × r
  target_modules: ['q_proj', 'v_proj']  # 只训练 q 和 v（减少模块）
  lora_dropout: 0.1
  bias: 'none'
```

**预期**：
- 参数：~1.5M（减少 50%）
- 性能：可能略降或持平
- 训练时间：减少约 50%

## 实验流程建议

### 步骤 1：单参数实验

1. **先调 r**（最重要）：
   - 基线：r=16（当前）
   - 实验：r=32, r=64
   - 评估：性能提升 vs 训练时间

2. **再调 alpha**：
   - 在最佳 r 基础上
   - 实验：alpha = r, 2r, 4r
   - 评估：性能提升

3. **最后调其他参数**：
   - dropout: 0.0, 0.1, 0.2
   - bias: 'none', 'lora_only'
   - target_modules: 考虑添加 MLP

### 步骤 2：组合实验

在单参数实验的基础上，组合最佳参数进行实验。

### 步骤 3：验证

- 在验证集上评估
- 检查过拟合情况
- 对比训练时间和性能提升

## 注意事项

1. **数据量**：
   - 数据量大：可以使用更大的 r 和更小的 dropout
   - 数据量小：使用较小的 r 和更大的 dropout

2. **过拟合监控**：
   - 观察训练集和验证集的性能差距
   - 如果差距过大，增加 dropout 或减小 r

3. **训练时间**：
   - r 增加会线性增加训练时间
   - 需要权衡性能和效率

4. **CLIP 架构**：
   - 不同 CLIP 模型的模块名称可能不同
   - 需要检查实际模块名称后再调整 target_modules

5. **任务特性**：
   - 视觉任务：可能需要更大的 vision encoder LoRA
   - 文本任务：可能需要更大的 text encoder LoRA
   - 可以分别调整两个编码器的 LoRA 参数

## 预期效果

基于当前结果（v2_lora ≈ v2），通过调参可能达到：

- **保守提升**（r=32）：+0.2-0.5%
- **平衡提升**（r=32, alpha=4r）：+0.5-1.0%
- **激进提升**（r=64, 添加 MLP）：+1.0-2.0%

**但需注意**：
- 当前 v2_lora 已经与 v2 性能相当，说明 LoRA 已经很好地适应了任务
- 进一步提升可能需要：
  1. 更大的 r（增加容量）
  2. 更多的训练数据
  3. 更长的训练时间
  4. 更好的训练策略（学习率调度等）

## 快速开始

创建新的配置文件进行实验：

```bash
# 复制当前配置
cp configs/train/lever_lm/v2/query_img_text_icd_img_text_lever_lm_lora.yaml \
   configs/train/lever_lm/v2/query_img_text_icd_img_text_lever_lm_lora_r32.yaml

# 修改 r 和 alpha
# r: 32
# lora_alpha: 64

# 训练新配置
bash scripts/train_lever_lm.sh vqa okvqa_local 0 query_img_text_icd_img_text rand_sampler qwen2.5_vl_3B v2_lora_r32
```

