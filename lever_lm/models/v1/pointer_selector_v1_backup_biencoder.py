"""
Pointer Selector V1: Bi-Encoder æŒ‡é’ˆé€‰æ‹©å™¨ï¼ˆåŸºç¡€ç‰ˆï¼‰

ç‰¹ç‚¹ï¼š
- è¾“å…¥ï¼šquery_emb [B, d], cand_emb [B, K, d]
- æ‰“åˆ†ï¼šscores = query_emb @ cand_emb^T
- æ¯æ­¥ masked softmaxï¼ˆå±è”½å·²é€‰ï¼‰
- æŸå¤±ï¼šäº¤å‰ç†µ + label smoothing

ä½œè€…: Lever-Plus Team
æ—¥æœŸ: 2025-10-26
å‚è€ƒ: yiyun.md V1 éƒ¨åˆ†
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Tuple, Optional


class PointerSelectorV1(nn.Module):
    """
    V1 ç‰ˆæœ¬ï¼šBi-Encoder æŒ‡é’ˆé€‰æ‹©å™¨
    
    æœ€ç®€å•çš„æŒ‡é’ˆç½‘ç»œå®ç°ï¼Œä½¿ç”¨ç‚¹ç§¯æ³¨æ„åŠ›æœºåˆ¶
    """
    
    def __init__(
        self,
        d_model: int = 256,
        K: int = 32,
        shot_num: int = 2,
        label_smoothing: float = 0.1,
        dropout: float = 0.1
    ):
        """
        åˆå§‹åŒ– V1 æ¨¡å‹
        
        Args:
            d_model: embedding ç»´åº¦ (é»˜è®¤ 256)
            K: å€™é€‰æ± å¤§å° (é»˜è®¤ 32)
            shot_num: éœ€è¦é€‰æ‹©çš„æ ·æœ¬æ•°é‡ (é»˜è®¤ 2)
            label_smoothing: æ ‡ç­¾å¹³æ»‘ç³»æ•° (é»˜è®¤ 0.1)
            dropout: dropout æ¯”ä¾‹ (é»˜è®¤ 0.1)
        """
        super().__init__()
        
        self.d_model = d_model
        self.K = K
        self.shot_num = shot_num
        self.label_smoothing = label_smoothing
        
        # å¯é€‰ï¼šquery æŠ•å½±å±‚ï¼ˆç”¨äºå¢å¼ºè¡¨è¾¾èƒ½åŠ›ï¼‰
        self.query_proj = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.LayerNorm(d_model),  # æ·»åŠ  LayerNorm é˜²æ­¢æ•°å€¼çˆ†ç‚¸
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_model, d_model),
            nn.LayerNorm(d_model)   # å½’ä¸€åŒ–å‰å†åŠ ä¸€å±‚ LayerNorm
        )
        
        # å¯é€‰ï¼šå€™é€‰æŠ•å½±å±‚
        self.cand_proj = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.LayerNorm(d_model),  # æ·»åŠ  LayerNorm é˜²æ­¢æ•°å€¼çˆ†ç‚¸
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_model, d_model),
            nn.LayerNorm(d_model)   # å½’ä¸€åŒ–å‰å†åŠ ä¸€å±‚ LayerNorm
        )
        
        # æ¸©åº¦å‚æ•°ï¼ˆç”¨äºæ§åˆ¶ softmax çš„å°–é”åº¦ï¼‰
        # ä¿®å¤ï¼šä»0.07å¢å¤§åˆ°0.1ï¼Œé¿å…åœ¨é«˜ç»´ç©ºé—´(d_model=768)æ—¶æ•°å€¼æº¢å‡º
        self.temperature = nn.Parameter(torch.ones(1) * 0.1)
        
        print(f"âœ“ PointerSelectorV1 åˆå§‹åŒ–å®Œæˆ")
        print(f"  - d_model: {d_model}")
        print(f"  - K (å€™é€‰æ± å¤§å°): {K}")
        print(f"  - shot_num: {shot_num}")
        print(f"  - label_smoothing: {label_smoothing}")
    
    def forward(
        self,
        query_emb: torch.Tensor,
        cand_emb: torch.Tensor,
        labels: Optional[torch.Tensor] = None,
        return_loss: bool = True
    ) -> dict:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            query_emb: [B, d] query embedding
            cand_emb: [B, K, d] å€™é€‰ embedding
            labels: [B, S] æ ‡ç­¾åºåˆ—ï¼ˆè®­ç»ƒæ—¶éœ€è¦ï¼‰
            return_loss: æ˜¯å¦è¿”å›æŸå¤±
        
        Returns:
            dict: {
                'logits': [B, S, K] æ¯æ­¥çš„ logits,
                'predictions': [B, S] é¢„æµ‹åºåˆ—,
                'loss': scalar (å¦‚æœ return_loss=True)
            }
        """
        batch_size = query_emb.shape[0]
        device = query_emb.device
        
        # æŠ•å½± query å’Œ candidates
        query_proj = self.query_proj(query_emb)  # [B, d]
        cand_proj = self.cand_proj(cand_emb)     # [B, K, d]
        
        # L2 å½’ä¸€åŒ–ï¼ˆæé«˜ç¨³å®šæ€§ï¼‰
        query_proj = F.normalize(query_proj, p=2, dim=-1)
        cand_proj = F.normalize(cand_proj, p=2, dim=-1)
        
        # å­˜å‚¨æ¯æ­¥çš„ logits å’Œé¢„æµ‹
        all_logits = []
        predictions = []
        
        # maskï¼šè®°å½•å·²é€‰æ‹©çš„å€™é€‰ï¼ˆåˆå§‹å…¨ä¸º Falseï¼‰
        selected_mask = torch.zeros(batch_size, self.K, dtype=torch.bool, device=device)
        
        # è‡ªå›å½’ç”Ÿæˆ shot_num æ­¥
        for step in range(self.shot_num):
            # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°ï¼šquery @ cand^T
            scores = torch.matmul(query_proj.unsqueeze(1), cand_proj.transpose(1, 2))  # [B, 1, K]
            scores = scores.squeeze(1) / self.temperature  # [B, K]ï¼Œæ¸©åº¦ç¼©æ”¾
            
            # åº”ç”¨ maskï¼šå°†å·²é€‰æ‹©çš„å€™é€‰è®¾ä¸º -inf
            scores = scores.masked_fill(selected_mask, float('-inf'))
            
            # ä¿å­˜ logits
            all_logits.append(scores)
            
            # é¢„æµ‹ï¼ˆè®­ç»ƒæ—¶ä¹Ÿè®¡ç®—ï¼Œç”¨äºç›‘æ§ï¼‰
            pred = scores.argmax(dim=-1)  # [B]
            predictions.append(pred)
            
            # æ›´æ–° maskï¼ˆè®­ç»ƒæ—¶ä½¿ç”¨çœŸå®æ ‡ç­¾ï¼Œæ¨ç†æ—¶ä½¿ç”¨é¢„æµ‹ï¼‰
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨éå°±åœ°æ“ä½œï¼Œé¿å…æ¢¯åº¦è®¡ç®—é”™è¯¯
            if labels is not None and step < labels.shape[1]:
                # è®­ç»ƒæ¨¡å¼ï¼šä½¿ç”¨çœŸå®æ ‡ç­¾æ›´æ–° maskï¼ˆTeacher Forcingï¼‰
                true_indices = labels[:, step]  # [B]
                # ä½¿ç”¨ scatter è€Œé scatter_ï¼Œåˆ›å»ºæ–°tensorè€Œéå°±åœ°ä¿®æ”¹
                selected_mask = selected_mask.scatter(1, true_indices.unsqueeze(1), True)
            else:
                # æ¨ç†æ¨¡å¼ï¼šä½¿ç”¨é¢„æµ‹æ›´æ–° mask
                selected_mask = selected_mask.scatter(1, pred.unsqueeze(1), True)
        
        # å †å ç»“æœ
        all_logits = torch.stack(all_logits, dim=1)  # [B, S, K]
        predictions = torch.stack(predictions, dim=1)  # [B, S]
        
        result = {
            'logits': all_logits,
            'predictions': predictions
        }
        
        # è®¡ç®—æŸå¤±ï¼ˆè®­ç»ƒæ—¶ï¼‰
        if return_loss and labels is not None:
            loss = self.compute_loss(all_logits, labels)
            result['loss'] = loss
        
        return result
    
    def compute_loss(
        self,
        logits: torch.Tensor,
        labels: torch.Tensor
    ) -> torch.Tensor:
        """
        è®¡ç®—æŸå¤±å‡½æ•°
        
        Args:
            logits: [B, S, K] æ¯æ­¥çš„ logits
            labels: [B, S] çœŸå®æ ‡ç­¾
        
        Returns:
            loss: æ ‡é‡æŸå¤±
        """
        batch_size, shot_num, K = logits.shape
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šå°† -inf æ›¿æ¢ä¸ºä¸€ä¸ªéå¸¸å°çš„å€¼ï¼Œé¿å…ä¸ label_smoothing å†²çª
        # label_smoothing ä¼šå°†éƒ¨åˆ†æ¦‚ç‡åˆ†é…ç»™æ‰€æœ‰ç±»åˆ«ï¼ŒåŒ…æ‹¬è¢« mask çš„ï¼ˆ-infï¼‰
        # è¿™ä¼šå¯¼è‡´ log(0) = -infï¼Œè¿›è€Œå¯¼è‡´ loss = inf
        # ä½¿ç”¨ -100ï¼šsoftmax(-100) â‰ˆ 3.7e-44ï¼Œæ¥è¿‘0ä½†ä¸ä¼šå¯¼è‡´æ•°å€¼é—®é¢˜
        logits_clamped = torch.clamp(logits, min=-100.0)  # æ›¿æ¢ -inf ä¸º -100
        
        # é‡å¡‘ä¸º [B*S, K] å’Œ [B*S]
        logits_flat = logits_clamped.reshape(-1, K)
        labels_flat = labels.reshape(-1)
        
        # äº¤å‰ç†µæŸå¤± + label smoothing
        loss = F.cross_entropy(
            logits_flat,
            labels_flat,
            label_smoothing=self.label_smoothing
        )
        
        return loss
    
    def predict(
        self,
        query_emb: torch.Tensor,
        cand_emb: torch.Tensor,
        top_k: int = 1
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        æ¨ç†æ¨¡å¼ï¼šé¢„æµ‹æœ€ä¼˜åºåˆ—
        
        Args:
            query_emb: [B, d]
            cand_emb: [B, K, d]
            top_k: æ¯æ­¥è¿”å› top-k ä¸ªå€™é€‰ï¼ˆé»˜è®¤ 1ï¼‰
        
        Returns:
            predictions: [B, S] é¢„æµ‹çš„ä½ç½®åºåˆ—
            scores: [B, S] å¯¹åº”çš„åˆ†æ•°
        """
        self.eval()
        with torch.no_grad():
            result = self.forward(query_emb, cand_emb, labels=None, return_loss=False)
            predictions = result['predictions']
            logits = result['logits']
            
            # è·å–æ¯æ­¥çš„æœ€å¤§åˆ†æ•°
            scores = logits.max(dim=-1)[0]  # [B, S]
            
            return predictions, scores


class PointerSelectorV1Config:
    """V1 æ¨¡å‹é…ç½®ç±»"""
    
    def __init__(
        self,
        d_model: int = 256,
        K: int = 32,
        shot_num: int = 2,
        label_smoothing: float = 0.1,
        dropout: float = 0.1
    ):
        self.d_model = d_model
        self.K = K
        self.shot_num = shot_num
        self.label_smoothing = label_smoothing
        self.dropout = dropout
    
    def to_dict(self):
        return {
            'd_model': self.d_model,
            'K': self.K,
            'shot_num': self.shot_num,
            'label_smoothing': self.label_smoothing,
            'dropout': self.dropout
        }


def build_model_v1(config: Optional[PointerSelectorV1Config] = None) -> PointerSelectorV1:
    """
    æ„å»º V1 æ¨¡å‹çš„å·¥å‚å‡½æ•°
    
    Args:
        config: æ¨¡å‹é…ç½®ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        PointerSelectorV1 å®ä¾‹
    """
    if config is None:
        config = PointerSelectorV1Config()
    
    model = PointerSelectorV1(
        d_model=config.d_model,
        K=config.K,
        shot_num=config.shot_num,
        label_smoothing=config.label_smoothing,
        dropout=config.dropout
    )
    
    return model


if __name__ == "__main__":
    """æµ‹è¯•ä»£ç """
    print("="*70)
    print("æµ‹è¯• PointerSelectorV1 æ¨¡å‹")
    print("="*70)
    
    # åˆ›å»ºæ¨¡å‹
    model = build_model_v1()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 4
    d_model = 256
    K = 32
    shot_num = 2
    
    query_emb = torch.randn(batch_size, d_model)
    cand_emb = torch.randn(batch_size, K, d_model)
    labels = torch.randint(0, K, (batch_size, shot_num))
    
    print(f"\nè¾“å…¥å½¢çŠ¶:")
    print(f"  query_emb: {query_emb.shape}")
    print(f"  cand_emb: {cand_emb.shape}")
    print(f"  labels: {labels.shape}")
    
    # å‰å‘ä¼ æ’­
    print(f"\nå‰å‘ä¼ æ’­...")
    result = model(query_emb, cand_emb, labels, return_loss=True)
    
    print(f"\nè¾“å‡º:")
    print(f"  logits: {result['logits'].shape}")
    print(f"  predictions: {result['predictions'].shape}")
    print(f"  loss: {result['loss'].item():.4f}")
    
    # æ¨ç†æ¨¡å¼
    print(f"\næ¨ç†æ¨¡å¼...")
    predictions, scores = model.predict(query_emb, cand_emb)
    print(f"  predictions: {predictions.shape}")
    print(f"  scores: {scores.shape}")
    
    print(f"\nç¤ºä¾‹é¢„æµ‹:")
    print(f"  labels:      {labels[0].tolist()}")
    print(f"  predictions: {predictions[0].tolist()}")
    print(f"  scores:      {scores[0].tolist()}")
    
    print("\n" + "="*70)
    print("âœ“ V1 æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")
    print("="*70)

