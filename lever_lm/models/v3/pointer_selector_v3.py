"""
Pointer Selector V3: çµæ´»åŸºç¡€æ¶æ„ + æ’åºå­¦ä¹ ï¼ˆRanking Learningï¼‰

ç‰¹ç‚¹ï¼š
- æ¶æ„ï¼šå¯é€‰æ‹©V1ï¼ˆBi-Encoderï¼‰æˆ–V2ï¼ˆ+ Cross-Attentionï¼‰ä½œä¸ºåŸºç¡€
- æ”¯æŒï¼šä»V1/V2 checkpointåŠ è½½åˆå§‹åŒ–
- å¢å¼ºï¼šåˆ©ç”¨æŸæœç´¢çš„å¤šä¸ªbeamè¿›è¡Œæ’åºå­¦ä¹ 
- æŸå¤±ï¼šäº¤å‰ç†µï¼ˆCEï¼‰+ æ’åºæŸå¤±ï¼ˆRanking Lossï¼‰
  - Pairwise: æ­£è´Ÿæ ·æœ¬å¯¹çš„margin loss
  - Listwise: KLæ•£åº¦è®©æ¨¡å‹åˆ†å¸ƒæ¥è¿‘beamåˆ†æ•°åˆ†å¸ƒ
- ç›®æ ‡ï¼šæå‡Top-kã€NDCGã€MRRç­‰æ’åºæŒ‡æ ‡

ä½œè€…: Lever-Plus Team
æ—¥æœŸ: 2025-10-29
å‚è€ƒ: yiyun.md V3 éƒ¨åˆ†
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Tuple, Optional, Dict, Any
import os
from collections import defaultdict
import numpy as np


class PointerSelectorV3(nn.Module):
    """
    V3 ç‰ˆæœ¬ï¼šçµæ´»åŸºç¡€æ¶æ„ + æ’åºå­¦ä¹ 
    
    å¯é€‰æ‹©V1ï¼ˆç®€å•Bi-Encoderï¼‰æˆ–V2ï¼ˆ+Cross-Attentionï¼‰ä½œä¸ºåŸºç¡€æ¶æ„
    """
    
    def __init__(
        self,
        d_model: int = 768,
        K: int = 32,
        shot_num: int = 6,
        label_smoothing: float = 0.0,
        dropout: float = 0.5,
        base_architecture: str = 'v2',  # 'v1' æˆ– 'v2'
        use_cross_attention: Optional[bool] = None,  # Noneæ—¶æ ¹æ®baseè‡ªåŠ¨è®¾ç½®
        ranking_loss_type: str = 'listwise',  # 'listwise' æˆ– 'pairwise'
        ranking_loss_weight: float = 0.5,  # æ’åºæŸå¤±æƒé‡
        ce_weight: float = 0.5  # äº¤å‰ç†µæƒé‡
    ):
        """
        åˆå§‹åŒ– V3 æ¨¡å‹
        
        Args:
            d_model: è¾“å…¥ embedding ç»´åº¦ (é»˜è®¤ 768)
            K: å€™é€‰æ± å¤§å° (é»˜è®¤ 32)
            shot_num: éœ€è¦é€‰æ‹©çš„æ ·æœ¬æ•°é‡ (é»˜è®¤ 6)
            label_smoothing: æ ‡ç­¾å¹³æ»‘ç³»æ•° (é»˜è®¤ 0.0)
            dropout: dropout æ¯”ä¾‹ (é»˜è®¤ 0.5)
            base_architecture: åŸºç¡€æ¶æ„ ('v1' æˆ– 'v2')
            use_cross_attention: æ˜¯å¦ä½¿ç”¨Cross-Attention (Noneæ—¶æ ¹æ®baseè‡ªåŠ¨è®¾ç½®)
            ranking_loss_type: æ’åºæŸå¤±ç±»å‹ ('listwise' æˆ– 'pairwise')
            ranking_loss_weight: æ’åºæŸå¤±æƒé‡
            ce_weight: äº¤å‰ç†µæƒé‡
        """
        super().__init__()
        
        self.d_model = d_model
        self.K = K
        self.shot_num = shot_num
        self.label_smoothing = label_smoothing
        self.base_architecture = base_architecture
        self.ranking_loss_type = ranking_loss_type
        self.ranking_loss_weight = ranking_loss_weight
        self.ce_weight = ce_weight
        
        # è‡ªåŠ¨è®¾ç½®Cross-Attention
        if use_cross_attention is None:
            use_cross_attention = (base_architecture == 'v2')
        self.use_cross_attention = use_cross_attention
        
        # æ ¹æ®åŸºç¡€æ¶æ„æ„å»ºç½‘ç»œ
        if base_architecture == 'v1':
            self._build_v1_architecture(d_model, dropout)
        elif base_architecture == 'v2':
            self._build_v2_architecture(d_model, dropout)
        else:
            raise ValueError(f"æœªçŸ¥çš„åŸºç¡€æ¶æ„: {base_architecture}, åªæ”¯æŒ 'v1' æˆ– 'v2'")
        
        print(f"âœ“ PointerSelectorV3 åˆå§‹åŒ–å®Œæˆ")
        print(f"  - åŸºç¡€æ¶æ„: {base_architecture.upper()}")
        print(f"  - d_model: {d_model}")
        print(f"  - K (å€™é€‰æ± å¤§å°): {K}")
        print(f"  - shot_num: {shot_num}")
        print(f"  - label_smoothing: {label_smoothing}")
        print(f"  - dropout: {dropout}")
        print(f"  - use_cross_attention: {use_cross_attention}")
        print(f"  - ranking_loss_type: {ranking_loss_type}")
        print(f"  - ranking_loss_weight: {ranking_loss_weight}")
        print(f"  - ce_weight: {ce_weight}")
        total_params = sum(p.numel() for p in self.parameters())
        print(f"  - å‚æ•°é‡: {total_params/1e6:.2f}M")
    
    def _build_v1_architecture(self, d_model: int, dropout: float):
        """
        æ„å»ºV1æ¶æ„ï¼šç®€å•Bi-Encoder
        
        ç»“æ„ï¼š2å±‚MLPæŠ•å½±
        """
        # Query æŠ•å½±å±‚ (2å±‚MLP)
        self.query_proj = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.LayerNorm(d_model),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_model, d_model),
            nn.LayerNorm(d_model)
        )
        
        # Candidate æŠ•å½±å±‚ (2å±‚MLP)
        self.cand_proj = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.LayerNorm(d_model),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_model, d_model),
            nn.LayerNorm(d_model)
        )
        
        # æ¸©åº¦å‚æ•°ï¼ˆå›ºå®šä¸º0.1ï¼‰
        self.temperature = 0.1
        
        # åˆå§‹åŒ–æƒé‡
        for m in self.query_proj:
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
        
        for m in self.cand_proj:
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def _build_v2_architecture(self, d_model: int, dropout: float):
        """
        æ„å»ºV2æ¶æ„ï¼šBi-Encoder + Cross-Attention
        
        ç»“æ„ï¼šé™ç»´ + Cross-Attention + å•å±‚æŠ•å½±
        """
        self.hidden_dim = 256  # V2çš„éšè—ç»´åº¦
        
        # è¾“å…¥æŠ•å½±ï¼ˆé™ç»´ï¼š768 -> 256ï¼‰
        if d_model != self.hidden_dim:
            self.input_proj = nn.Linear(d_model, self.hidden_dim, bias=False)
        else:
            self.input_proj = nn.Identity()
        
        # Cross-Attention å±‚
        self.cross_attn = nn.MultiheadAttention(
            embed_dim=self.hidden_dim,
            num_heads=1,
            dropout=dropout,
            batch_first=True
        )
        
        # Layer Normalization
        self.attn_norm = nn.LayerNorm(self.hidden_dim)
        
        # Query/CandidateæŠ•å½±å±‚ï¼ˆå•å±‚ï¼‰
        self.query_proj = nn.Linear(self.hidden_dim, self.hidden_dim, bias=False)
        self.cand_proj = nn.Linear(self.hidden_dim, self.hidden_dim, bias=False)
        
        # Dropout
        self.dropout = nn.Dropout(dropout)
        
        # æ¸©åº¦å‚æ•°
        self.temperature = torch.tensor([0.1], dtype=torch.float32)
        
        # åˆå§‹åŒ–æƒé‡
        if not isinstance(self.input_proj, nn.Identity):
            nn.init.xavier_uniform_(self.input_proj.weight)
        
        # Eyeåˆå§‹åŒ– + å°æ‰°åŠ¨
        nn.init.eye_(self.query_proj.weight)
        nn.init.eye_(self.cand_proj.weight)
        
        with torch.no_grad():
            self.query_proj.weight.add_(torch.randn_like(self.query_proj.weight) * 0.01)
            self.cand_proj.weight.add_(torch.randn_like(self.cand_proj.weight) * 0.01)
    
    def forward(
        self,
        query_emb: torch.Tensor,
        cand_emb: torch.Tensor,
        labels: Optional[torch.Tensor] = None,
        return_loss: bool = True,
        beam_scores: Optional[torch.Tensor] = None,  # å…¼å®¹æ—§ç‰ˆ
        all_beams_info: Optional[list] = None,  # V3æ–°å¢ï¼šæ‰€æœ‰beamä¿¡æ¯
        cands: Optional[list] = None  # V3æ–°å¢ï¼šå€™é€‰æ± IDåˆ—è¡¨
    ) -> dict:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            query_emb: [B, d] æˆ– [B, 2, d] query embedding  
            cand_emb: [B, K, d] æˆ– [B, K, 2, d] å€™é€‰ embedding
            labels: [B, S] æ ‡ç­¾åºåˆ—ï¼ˆè®­ç»ƒæ—¶éœ€è¦ï¼‰
            return_loss: æ˜¯å¦è¿”å›æŸå¤±
            beam_scores: å…¼å®¹æ—§ç‰ˆ
            all_beams_info: æ‰€æœ‰beamä¿¡æ¯ï¼Œæ ¼å¼ï¼š[{"id_seq": [...], "score": 0.85}, ...]
            cands: å€™é€‰æ± IDåˆ—è¡¨ [id1, id2, ..., idK]
        
        Returns:
            dict: {
                'logits': [B, S, K],
                'predictions': [B, S],
                'loss': scalar (å¦‚æœ return_loss=True)
            }
        """
        batch_size = query_emb.shape[0]
        device = query_emb.device
        
        # å¤„ç†å¤šæ¨¡æ€è¾“å…¥ [B, 2, d] -> [B, d]
        if len(query_emb.shape) == 3:
            query_emb = query_emb.mean(dim=1)  # å¹³å‡æ± åŒ–
        if len(cand_emb.shape) == 4:
            cand_emb = cand_emb.mean(dim=2)  # [B, K, 2, d] -> [B, K, d]
        
        # æ ¹æ®åŸºç¡€æ¶æ„è¿›è¡Œå‰å‘ä¼ æ’­
        if self.base_architecture == 'v1':
            query_proj, cand_proj = self._forward_v1(query_emb, cand_emb)
        else:  # v2
            query_proj, cand_proj = self._forward_v2(query_emb, cand_emb)
        
        # å­˜å‚¨æ¯æ­¥çš„ logits å’Œé¢„æµ‹
        all_logits = []
        predictions = []
        
        # å½“å‰ query çŠ¶æ€
        current_query = query_proj
        
        # maskï¼šè®°å½•å·²é€‰æ‹©çš„å€™é€‰
        selected_mask = torch.zeros(batch_size, self.K, dtype=torch.bool, device=device)
        
        # è‡ªå›å½’ç”Ÿæˆ
        for step in range(self.shot_num):
            # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
            scores = torch.matmul(current_query.unsqueeze(1), cand_proj.transpose(1, 2)).squeeze(1)  # [B, K]
            
            # æ¸©åº¦ç¼©æ”¾
            if isinstance(self.temperature, torch.Tensor):
                temperature = self.temperature.to(device)
                scores = scores / temperature
            else:
                scores = scores / self.temperature
            
            # åº”ç”¨ mask
            scores = scores.masked_fill(selected_mask, -100.0)
            all_logits.append(scores)
            
            # é¢„æµ‹
            pred = scores.argmax(dim=-1)  # [B]
            predictions.append(pred)
            
            # æ›´æ–° mask (Teacher Forcing æˆ–æ¨ç†)
            if labels is not None and step < labels.shape[1]:
                true_indices = labels[:, step]
                selected_mask = selected_mask.scatter(1, true_indices.unsqueeze(1), True)
            else:
                selected_mask = selected_mask.scatter(1, pred.unsqueeze(1), True)
        
        # å †å ç»“æœ
        all_logits = torch.stack(all_logits, dim=1)  # [B, S, K]
        predictions = torch.stack(predictions, dim=1)  # [B, S]
        
        result = {
            'logits': all_logits,
            'predictions': predictions
        }
        
        # è®¡ç®—æŸå¤±
        if return_loss and labels is not None:
            loss = self.compute_loss(all_logits, labels, all_beams_info, cands)
            result['loss'] = loss
        
        return result
    
    def _forward_v1(
        self,
        query_emb: torch.Tensor,
        cand_emb: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """V1å‰å‘ä¼ æ’­"""
        # æŠ•å½±
        query_proj = self.query_proj(query_emb)  # [B, d]
        cand_proj = self.cand_proj(cand_emb)     # [B, K, d]
        
        # L2 å½’ä¸€åŒ–
        query_proj = F.normalize(query_proj, dim=-1)
        cand_proj = F.normalize(cand_proj, dim=-1)
        
        return query_proj, cand_proj
    
    def _forward_v2(
        self,
        query_emb: torch.Tensor,
        cand_emb: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """V2å‰å‘ä¼ æ’­"""
        batch_size = query_emb.shape[0]
        
        # é™ç»´
        query_reduced = self.input_proj(query_emb)  # [B, 256]
        cand_reduced = self.input_proj(cand_emb.reshape(-1, self.d_model))  # [B*K, 256]
        cand_reduced = cand_reduced.reshape(batch_size, self.K, self.hidden_dim)  # [B, K, 256]
        
        # Cross-Attentionå¢å¼º
        query_enhanced, _ = self.cross_attn(
            query_reduced.unsqueeze(1),  # [B, 1, 256]
            cand_reduced,                 # [B, K, 256]
            cand_reduced
        )
        query_enhanced = query_enhanced.squeeze(1)  # [B, 256]
        
        # Residual + LayerNorm
        query_enhanced = self.attn_norm(query_reduced + query_enhanced)
        
        # æŠ•å½±
        query_proj = self.query_proj(query_enhanced)  # [B, 256]
        cand_proj = self.cand_proj(cand_reduced)       # [B, K, 256]
        
        # Dropout
        query_proj = self.dropout(query_proj)
        cand_proj = self.dropout(cand_proj)
        
        # L2 å½’ä¸€åŒ–
        query_proj = F.normalize(query_proj, dim=-1)
        cand_proj = F.normalize(cand_proj, dim=-1)
        
        return query_proj, cand_proj
    
    def compute_loss(
        self,
        logits: torch.Tensor,
        labels: torch.Tensor,
        all_beams_info: Optional[list] = None,
        cands: Optional[list] = None
    ) -> torch.Tensor:
        """
        è®¡ç®—æŸå¤±ï¼šCE + Ranking Loss
        
        Args:
            logits: [B, S, K]
            labels: [B, S]
            all_beams_info: Batchçš„beamä¿¡æ¯ï¼Œæ ¼å¼ï¼š[[beam1, beam2], [beam1, beam2], ...] (Bä¸ªæ ·æœ¬)
            cands: Batchçš„å€™é€‰æ± IDåˆ—è¡¨ï¼Œæ ¼å¼ï¼š[[id1, id2, ...], [id1, id2, ...], ...] (Bä¸ªæ ·æœ¬)
        """
        batch_size, shot_num, K = logits.shape
        
        # 1. äº¤å‰ç†µæŸå¤±
        logits_flat = logits.reshape(-1, K)
        labels_flat = labels.reshape(-1)
        
        ce_loss = F.cross_entropy(
            logits_flat,
            labels_flat,
            label_smoothing=self.label_smoothing
        )
        
        # 2. æ’åºæŸå¤±
        ranking_loss = torch.tensor(0.0, device=logits.device)
        if all_beams_info is not None and cands is not None and self.ranking_loss_weight > 0:
            # é€æ ·æœ¬è®¡ç®—æ’åºæŸå¤±
            batch_ranking_losses = []
            for i in range(batch_size):
                sample_logits = logits[i:i+1]  # [1, S, K]
                sample_beams = all_beams_info[i]  # è¯¥æ ·æœ¬çš„beamåˆ—è¡¨
                sample_cands = cands[i]  # è¯¥æ ·æœ¬çš„å€™é€‰IDåˆ—è¡¨
                
                # è·³è¿‡æ²¡æœ‰beamä¿¡æ¯çš„æ ·æœ¬
                if len(sample_beams) == 0:
                    continue
                
                if self.ranking_loss_type == 'listwise':
                    sample_loss = self._listwise_ranking_loss(sample_logits, sample_beams, sample_cands)
                elif self.ranking_loss_type == 'pairwise':
                    sample_loss = self._pairwise_ranking_loss(sample_logits, sample_beams, sample_cands)
                else:
                    continue
                
                batch_ranking_losses.append(sample_loss)
            
            # å¹³å‡batchçš„æ’åºæŸå¤±
            if len(batch_ranking_losses) > 0:
                ranking_loss = torch.stack(batch_ranking_losses).mean()
        
        # 3. åŠ¨æ€è°ƒæ•´æ’åºæŸå¤±æƒé‡ï¼ˆæ ¹æ® shot_numï¼‰
        # é«˜ shot æ•°æ—¶ï¼Œæ’åºä¿¡æ¯æ›´é‡è¦ï¼Œå¢å¤§æƒé‡ï¼ˆæ›´æ¿€è¿›çš„ç¼©æ”¾ï¼Œé’ˆå¯¹é«˜shotæ•°ä¼˜åŒ–ï¼‰
        # shot_num=1: æƒé‡ * 0.4, shot_num=2: æƒé‡ * 1.0, shot_num=3: æƒé‡ * 2.5, shot_num=4: æƒé‡ * 5.0
        if shot_num == 1:
            dynamic_weight_scale = 0.4
        elif shot_num == 2:
            dynamic_weight_scale = 1.0
        elif shot_num == 3:
            dynamic_weight_scale = 2.5
        else:  # shot_num >= 4
            dynamic_weight_scale = 5.0
        effective_ranking_weight = self.ranking_loss_weight * dynamic_weight_scale
        
        # 4. åŠ æƒç»„åˆ
        total_loss = self.ce_weight * ce_loss + effective_ranking_weight * ranking_loss
        
        return total_loss
    
    def _listwise_ranking_loss(
        self,
        logits: torch.Tensor,
        all_beams_info: list,
        cands: list
    ) -> torch.Tensor:
        """
        Listwiseæ’åºæŸå¤±ï¼šKLæ•£åº¦
        
        è®©æ¨¡å‹çš„å€™é€‰åˆ†å¸ƒæ¥è¿‘beamåˆ†æ•°çš„åˆ†å¸ƒ
        æ”¹è¿›ï¼š
        1. åªä½¿ç”¨ top-k beamsï¼ˆå¿½ç•¥ä½è´¨é‡ beamï¼‰
        2. è€ƒè™‘å€™é€‰åœ¨ beam åºåˆ—ä¸­çš„ä½ç½®ï¼ˆä½ç½®è¶Šé å‰ï¼Œé‡è¦æ€§è¶Šé«˜ï¼‰
        3. åŠ¨æ€æ¸©åº¦å‚æ•°ï¼ˆæ ¹æ®å€™é€‰å¾—åˆ†èŒƒå›´è°ƒæ•´ï¼‰
        """
        batch_size, shot_num, K = logits.shape
        device = logits.device
        
        # æ„å»ºå€™é€‰IDåˆ°ä½ç½®çš„æ˜ å°„
        cand_to_pos = {int(cand_id): pos for pos, cand_id in enumerate(cands)}
        
        # æŒ‰ beam åˆ†æ•°æ’åºï¼Œåªä½¿ç”¨ top-k beamsï¼ˆä¿ç•™å‰ 50% æˆ–è‡³å°‘ 2 ä¸ªï¼‰
        if len(all_beams_info) == 0:
            return torch.tensor(0.0, device=device)
        
        # æŒ‰åˆ†æ•°æ’åº beams
        sorted_beams = sorted(all_beams_info, key=lambda x: x["score"], reverse=True)
        # åªä½¿ç”¨ top-k beamsï¼ˆæ›´ä¸¥æ ¼çš„é€‰æ‹©ï¼šé«˜shotæ•°æ—¶åªä¿ç•™å‰20%ï¼Œä½shotæ•°æ—¶ä¿ç•™å‰50%ï¼‰
        # é«˜shotæ•°æ—¶ï¼Œbeamè´¨é‡å·®å¼‚æ›´æ˜æ˜¾ï¼Œåªå…³æ³¨æœ€é«˜è´¨é‡çš„beams
        if shot_num >= 3:
            top_k_ratio = 0.2  # é«˜shotæ•°ï¼šåªä¿ç•™å‰20%ï¼ˆæ›´ä¸¥æ ¼ï¼‰
        else:
            top_k_ratio = 0.5  # ä½shotæ•°ï¼šä¿ç•™å‰50%
        top_k = max(2, int(len(sorted_beams) * top_k_ratio))
        top_beams = sorted_beams[:top_k]
        
        # æ”¶é›†æ¯ä¸ªå€™é€‰çš„å¾—åˆ†ï¼ˆè€ƒè™‘ä½ç½®æƒé‡ï¼šä½ç½®è¶Šé å‰ï¼Œæƒé‡è¶Šå¤§ï¼‰
        candidate_weighted_scores = defaultdict(lambda: {'sum': 0.0, 'weight': 0.0})
        
        # å½’ä¸€åŒ– top beams çš„åˆ†æ•°ä½œä¸ºæƒé‡
        top_beam_scores = [beam["score"] for beam in top_beams]
        top_beam_scores_tensor = torch.tensor(top_beam_scores, device=device)
        beam_weights = F.softmax(top_beam_scores_tensor, dim=0)
        
        for beam_idx, beam in enumerate(top_beams):
            beam_seq = beam["id_seq"][:-1]  # å»æ‰æœ«å°¾çš„query_id
            beam_weight = beam_weights[beam_idx].item()
            
            # ä½ç½®æƒé‡ï¼šåºåˆ—ä¸­è¶Šé å‰çš„å€™é€‰ï¼Œæƒé‡è¶Šå¤§
            # é«˜shotæ•°æ—¶ä½¿ç”¨æ›´æ¿€è¿›çš„è¡°å‡ï¼Œæ›´å¼ºè°ƒåºåˆ—å‰é¢çš„å€™é€‰
            if shot_num >= 4:
                decay_rate = 0.6  # shot_num=4: æœ€æ¿€è¿›ï¼ˆ1.0, 0.6, 0.36, ...ï¼‰
            elif shot_num >= 3:
                decay_rate = 0.65  # shot_num=3: è¾ƒæ¿€è¿›ï¼ˆ1.0, 0.65, 0.42, ...ï¼‰
            else:
                decay_rate = 0.8  # shot_num<3: è¾ƒæ¸©å’Œï¼ˆ1.0, 0.8, 0.64, ...ï¼‰
            for seq_pos, icd_id in enumerate(beam_seq):
                if icd_id in cand_to_pos:
                    pos = cand_to_pos[icd_id]
                    # ä½ç½®æƒé‡ï¼šé«˜shotæ•°æ—¶æ›´æ¿€è¿›ï¼Œæ›´å¼ºè°ƒåºåˆ—å‰é¢çš„å€™é€‰
                    position_weight = decay_rate ** seq_pos
                    # ç»¼åˆæƒé‡ = beamæƒé‡ * ä½ç½®æƒé‡
                    combined_weight = beam_weight * position_weight
                    # ä½¿ç”¨ beam åˆ†æ•°å’Œç»¼åˆæƒé‡
                    candidate_weighted_scores[pos]['sum'] += beam["score"] * combined_weight
                    candidate_weighted_scores[pos]['weight'] += combined_weight
        
        # è®¡ç®—æ¯ä¸ªå€™é€‰çš„åŠ æƒå¹³å‡å¾—åˆ†
        candidate_avg_scores = torch.zeros(K, device=device)
        for pos, data in candidate_weighted_scores.items():
            if data['weight'] > 0:
                candidate_avg_scores[pos] = data['sum'] / data['weight']
        
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„å€™é€‰å¾—åˆ†ï¼Œè¿”å›0
        if candidate_avg_scores.sum() == 0:
            return torch.tensor(0.0, device=device)
        
        # åŠ¨æ€æ¸©åº¦å‚æ•°ï¼šæ ¹æ®å¾—åˆ†èŒƒå›´å’Œ shot_num è°ƒæ•´
        # é«˜ shot æ•°æ—¶ä½¿ç”¨æ›´å°çš„æ¸©åº¦ï¼ˆæ›´å°–é”çš„åˆ†å¸ƒï¼‰ï¼Œæ›´å¼ºè°ƒæ’åºå·®å¼‚
        score_range = candidate_avg_scores.max() - candidate_avg_scores.min()
        if score_range > 0:
            # åŸºç¡€æ¸©åº¦ï¼šæ ¹æ®å¾—åˆ†èŒƒå›´è°ƒæ•´
            base_temp = 0.3 + 0.2 * (1.0 - min(score_range / 10.0, 1.0))
            # shot_num è¶Šå¤§ï¼Œæ¸©åº¦è¶Šå°ï¼ˆæ›´å°–é”ï¼‰ï¼Œé«˜shotæ•°æ—¶æ›´æ¿€è¿›
            if shot_num >= 4:
                # shot_num=4: æœ€æ¿€è¿›çš„æ¸©åº¦ç¼©æ”¾
                shot_temp_scale = 0.4  # ç›´æ¥è®¾ç½®ä¸º0.4
            elif shot_num >= 3:
                # shot_num=3: è¾ƒæ¿€è¿›çš„æ¸©åº¦ç¼©æ”¾
                shot_temp_scale = 0.6
            else:
                # ä½shotæ•°ï¼šè¾ƒæ¸©å’Œçš„ç¼©æ”¾
                shot_temp_scale = 1.0 - 0.1 * (shot_num - 1)  # shot_num=1: 1.0, shot_num=2: 0.9
            temperature = base_temp * max(shot_temp_scale, 0.3)  # æœ€å°æ¸©åº¦ 0.3
        else:
            # é»˜è®¤æ¸©åº¦ä¹Ÿæ ¹æ® shot_num è°ƒæ•´ï¼Œé«˜shotæ•°æ—¶æ›´å°ï¼ˆæ›´æ¿€è¿›ï¼‰
            if shot_num >= 4:
                temperature = 0.15  # shot_num=4: æœ€å°æ¸©åº¦ï¼Œæœ€å°–é”çš„åˆ†å¸ƒ
            elif shot_num >= 3:
                temperature = 0.25  # shot_num=3: è¾ƒå°æ¸©åº¦
            else:
                temperature = 0.5 - 0.05 * (shot_num - 1)  # shot_num=1: 0.5, shot_num=2: 0.45
            temperature = max(temperature, 0.15)  # æœ€å°æ¸©åº¦ 0.15ï¼ˆæ›´æ¿€è¿›ï¼‰
        
        # æ„å»ºç›®æ ‡åˆ†å¸ƒ
        target_dist = F.softmax(candidate_avg_scores / temperature, dim=-1)  # [K]
        
        # æ¨¡å‹çš„å¹³å‡æ¦‚ç‡åˆ†å¸ƒ
        model_probs = F.softmax(logits, dim=-1)  # [B, S, K]
        model_probs_avg = model_probs.mean(dim=1)  # [B, K]
        
        # KLæ•£åº¦
        target_dist_batch = target_dist.unsqueeze(0).expand(batch_size, -1)  # [B, K]
        
        kl_loss = F.kl_div(
            torch.log(model_probs_avg + 1e-10),
            target_dist_batch,
            reduction='batchmean'
        )
        
        return kl_loss
    
    def _pairwise_ranking_loss(
        self,
        logits: torch.Tensor,
        all_beams_info: list,
        cands: list
    ) -> torch.Tensor:
        """
        Pairwiseæ’åºæŸå¤±ï¼šMargin Loss
        
        è¦æ±‚å¥½çš„å€™é€‰å¾—åˆ† > å·®çš„å€™é€‰å¾—åˆ† + margin
        """
        batch_size, shot_num, K = logits.shape
        device = logits.device
        
        # æ„å»ºæ˜ å°„
        cand_to_pos = {int(cand_id): pos for pos, cand_id in enumerate(cands)}
        
        # æ”¶é›†å€™é€‰å¾—åˆ†
        candidate_scores = defaultdict(list)
        for beam in all_beams_info:
            beam_seq = beam["id_seq"][:-1]
            score = beam["score"]
            for icd_id in beam_seq:
                if icd_id in cand_to_pos:
                    pos = cand_to_pos[icd_id]
                    candidate_scores[pos].append(score)
        
        # è®¡ç®—å¹³å‡å¾—åˆ†
        candidate_avg_scores = {}
        for pos, scores in candidate_scores.items():
            candidate_avg_scores[pos] = float(np.mean(scores))
        
        if len(candidate_avg_scores) < 2:
            return torch.tensor(0.0, device=device)
        
        # æŒ‰å¾—åˆ†æ’åº
        sorted_cands = sorted(candidate_avg_scores.items(), key=lambda x: x[1], reverse=True)
        
        # åˆ’åˆ†æ­£è´Ÿæ ·æœ¬
        mid_point = len(sorted_cands) // 2
        positive_cands = [pos for pos, _ in sorted_cands[:mid_point]]
        negative_cands = [pos for pos, _ in sorted_cands[mid_point:]]
        
        if len(positive_cands) == 0 or len(negative_cands) == 0:
            return torch.tensor(0.0, device=device)
        
        # è®¡ç®—æ¨¡å‹å¾—åˆ†
        model_scores_avg = logits.mean(dim=1)  # [B, K]
        
        # Pairwise margin loss
        total_loss = 0.0
        num_pairs = 0
        margin = 1.0
        
        for pos_idx in positive_cands:
            for neg_idx in negative_cands:
                pos_score = model_scores_avg[0, pos_idx]
                neg_score = model_scores_avg[0, neg_idx]
                
                pair_loss = torch.clamp(margin + neg_score - pos_score, min=0)
                total_loss += pair_loss
                num_pairs += 1
        
        if num_pairs > 0:
            return total_loss / num_pairs
        else:
            return torch.tensor(0.0, device=device)
    
    def predict(
        self,
        query_emb: torch.Tensor,
        cand_emb: torch.Tensor,
        top_k: int = 1
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        æ¨ç†æ¨¡å¼
        
        Args:
            query_emb: [B, d]
            cand_emb: [B, K, d]
            top_k: æ¯æ­¥è¿”å› top-k
        
        Returns:
            predictions: [B, S]
            scores: [B, S]
        """
        self.eval()
        with torch.no_grad():
            result = self.forward(query_emb, cand_emb, labels=None, return_loss=False)
            predictions = result['predictions']
            logits = result['logits']
            
            # è·å–æ¯æ­¥çš„æœ€å¤§åˆ†æ•°
            scores = logits.max(dim=-1)[0]  # [B, S]
            
            return predictions, scores


class PointerSelectorV3Config:
    """V3 æ¨¡å‹é…ç½®ç±»"""
    
    def __init__(
        self,
        d_model: int = 768,
        K: int = 32,
        shot_num: int = 6,
        label_smoothing: float = 0.0,
        dropout: float = 0.5,
        base_architecture: str = 'v2',
        use_cross_attention: Optional[bool] = None,
        ranking_loss_type: str = 'listwise',
        ranking_loss_weight: float = 0.5,
        ce_weight: float = 0.5
    ):
        self.d_model = d_model
        self.K = K
        self.shot_num = shot_num
        self.label_smoothing = label_smoothing
        self.dropout = dropout
        self.base_architecture = base_architecture
        self.use_cross_attention = use_cross_attention
        self.ranking_loss_type = ranking_loss_type
        self.ranking_loss_weight = ranking_loss_weight
        self.ce_weight = ce_weight
    
    def to_dict(self):
        return {
            'd_model': self.d_model,
            'K': self.K,
            'shot_num': self.shot_num,
            'label_smoothing': self.label_smoothing,
            'dropout': self.dropout,
            'base_architecture': self.base_architecture,
            'use_cross_attention': self.use_cross_attention,
            'ranking_loss_type': self.ranking_loss_type,
            'ranking_loss_weight': self.ranking_loss_weight,
            'ce_weight': self.ce_weight
        }


def build_model_v3(config: Optional[PointerSelectorV3Config] = None) -> PointerSelectorV3:
    """
    æ„å»º V3 æ¨¡å‹çš„å·¥å‚å‡½æ•°
    """
    if config is None:
        config = PointerSelectorV3Config()
    
    model = PointerSelectorV3(
        d_model=config.d_model,
        K=config.K,
        shot_num=config.shot_num,
        label_smoothing=config.label_smoothing,
        dropout=config.dropout,
        base_architecture=config.base_architecture,
        use_cross_attention=config.use_cross_attention,
        ranking_loss_type=config.ranking_loss_type,
        ranking_loss_weight=config.ranking_loss_weight,
        ce_weight=config.ce_weight
    )
    
    return model


def load_v3_from_checkpoint(
    checkpoint_path: str,
    base_model_version: str = 'v2',
    ranking_loss_type: str = 'listwise',
    ranking_loss_weight: float = 0.5,
    ce_weight: float = 0.5,
    freeze_base: bool = False,
    device: torch.device = None
) -> PointerSelectorV3:
    """
    ä»V1æˆ–V2çš„checkpointåˆå§‹åŒ–V3æ¨¡å‹
    
    Args:
        checkpoint_path: V1æˆ–V2çš„checkpointè·¯å¾„
        base_model_version: åŸºç¡€æ¨¡å‹ç‰ˆæœ¬ ('v1' æˆ– 'v2')
        ranking_loss_type: æ’åºæŸå¤±ç±»å‹
        ranking_loss_weight: æ’åºæŸå¤±æƒé‡
        ce_weight: äº¤å‰ç†µæƒé‡
        freeze_base: æ˜¯å¦å†»ç»“åŸºç¡€æ¶æ„ï¼ˆåªè®­ç»ƒæ’åºç›¸å…³å‚æ•°ï¼‰
        device: è®¾å¤‡
    
    Returns:
        åˆå§‹åŒ–å¥½çš„V3æ¨¡å‹
    """
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    print(f"ä» {base_model_version.upper()} checkpoint åŠ è½½ V3 æ¨¡å‹...")
    print(f"Checkpoint: {checkpoint_path}")
    
    # åŠ è½½checkpoint
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # æå–é…ç½®
    if 'model_config' in checkpoint:
        config_dict = checkpoint['model_config']
        d_model = config_dict.get('d_model', 768)
        K = config_dict.get('K', 32)
        shot_num = config_dict.get('shot_num', 6)
        label_smoothing = config_dict.get('label_smoothing', 0.0)
        dropout = config_dict.get('dropout', 0.5)
    else:
        # ä½¿ç”¨é»˜è®¤é…ç½®
        d_model = 768
        K = 32
        shot_num = 6
        label_smoothing = 0.0
        dropout = 0.5
    
    # åˆ›å»ºV3æ¨¡å‹
    model = PointerSelectorV3(
        d_model=d_model,
        K=K,
        shot_num=shot_num,
        label_smoothing=label_smoothing,
        dropout=dropout,
        base_architecture=base_model_version,
        ranking_loss_type=ranking_loss_type,
        ranking_loss_weight=ranking_loss_weight,
        ce_weight=ce_weight
    )
    
    # åŠ è½½åŸºç¡€æ¶æ„çš„å‚æ•°ï¼ˆstrict=Falseå…è®¸éƒ¨åˆ†åŒ¹é…ï¼‰
    if 'model_state_dict' in checkpoint:
        state_dict = checkpoint['model_state_dict']
    else:
        state_dict = checkpoint
    
    # åŠ è½½å‚æ•°
    missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)
    
    print(f"âœ“ æˆåŠŸåŠ è½½ {base_model_version.upper()} å‚æ•°")
    if missing_keys:
        print(f"  ç¼ºå¤±çš„é”®ï¼ˆV3æ–°å¢ï¼‰: {len(missing_keys)} ä¸ª")
    if unexpected_keys:
        print(f"  æœªä½¿ç”¨çš„é”®: {len(unexpected_keys)} ä¸ª")
    
    # å¯é€‰ï¼šå†»ç»“åŸºç¡€æ¶æ„
    if freeze_base:
        print(f"ğŸ”’ å†»ç»“åŸºç¡€æ¶æ„å‚æ•°ï¼Œåªè®­ç»ƒæ’åºç›¸å…³å‚æ•°")
        for name, param in model.named_parameters():
            # V3æ²¡æœ‰æ–°å¢å‚æ•°å±‚ï¼Œæ‰€ä»¥è¿™é‡Œæš‚æ—¶å…¨éƒ¨è§£å†»
            # å®é™…ä¸ŠV3çš„æ’åºæŸå¤±æ˜¯é€šè¿‡æŸå¤±å‡½æ•°å®ç°çš„ï¼Œä¸éœ€è¦é¢å¤–å‚æ•°
            param.requires_grad = True
    
    return model.to(device)


if __name__ == "__main__":
    """æµ‹è¯•ä»£ç """
    print("="*70)
    print("æµ‹è¯• PointerSelectorV3 æ¨¡å‹")
    print("="*70)
    
    # æµ‹è¯•V3-V2æ¶æ„
    print("\nã€æµ‹è¯•1ã€‘V3-V2æ¶æ„ï¼ˆfrom scratchï¼‰")
    model_v3_v2 = build_model_v3(PointerSelectorV3Config(base_architecture='v2'))
    
    # æµ‹è¯•V3-V1æ¶æ„
    print("\nã€æµ‹è¯•2ã€‘V3-V1æ¶æ„ï¼ˆfrom scratchï¼‰")
    model_v3_v1 = build_model_v3(PointerSelectorV3Config(base_architecture='v1'))
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 4
    d_model = 768
    K = 32
    shot_num = 6
    
    query_emb = torch.randn(batch_size, d_model)
    cand_emb = torch.randn(batch_size, K, d_model)
    labels = torch.randint(0, K, (batch_size, shot_num))
    
    print(f"\nã€æµ‹è¯•3ã€‘å‰å‘ä¼ æ’­")
    print(f"è¾“å…¥å½¢çŠ¶:")
    print(f"  query_emb: {query_emb.shape}")
    print(f"  cand_emb: {cand_emb.shape}")
    print(f"  labels: {labels.shape}")
    
    # å‰å‘ä¼ æ’­
    result = model_v3_v2(query_emb, cand_emb, labels, return_loss=True)
    
    print(f"\nè¾“å‡º:")
    print(f"  logits: {result['logits'].shape}")
    print(f"  predictions: {result['predictions'].shape}")
    print(f"  loss: {result['loss'].item():.4f}")
    
    print("\n" + "="*70)
    print("âœ“ V3 æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")
    print("="*70)
