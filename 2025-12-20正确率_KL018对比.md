# Lever-Plus v3 GRPO 正确率对比报告（KL_BETA=0.18 vs 0.15 vs 0.12）

## 测试配置

- **数据集**: OKVQA
- **推理模型**: Qwen2.5-VL-3B-Instruct
- **采样器**: RandSampler
- **测试日期**: 2025-12-21
- **对比模型**:
  - **KL_BETA=0.18**: GRPO epoch 1, 2, 3（本次训练）
  - **KL_BETA=0.15**: GRPO epoch 1, 2（参考：2025-12-20正确率.md）
  - **KL_BETA=0.12**: GRPO epoch 1, 2, 3（参考：2025-12-20正确率_KL012对比.md）

---

## 训练配置对比

### KL_BETA=0.18 训练配置

| 参数 | 值 |
|------|-----|
| 基础 checkpoint | RCE epoch 5 |
| GRPO epochs | 3 |
| GRPO LR | 5e-6 |
| **KL beta** | **0.18** |
| 冻结 backbone | 是（只训练 50.1% 参数）|
| reward_mode | hard_plus_soft |
| RL 数据 | rl_data_RandSampler_Qwen2_5-VL-3B-Instruct.json |

### KL_BETA=0.15 训练配置（参考）

| 参数 | 值 |
|------|-----|
| 基础 checkpoint | RCE epoch 2 (val_loss=7.8863) |
| GRPO epochs | 3 |
| GRPO LR | 5e-6 |
| **KL beta** | **0.15** |
| 冻结 backbone | 是（只训练 50.1% 参数）|
| reward_mode | hard_plus_soft |
| RL 数据 | rl_data_k64_v3.json (800 queries, 53.3% 正样本) |

### KL_BETA=0.12 训练配置（参考）

| 参数 | 值 |
|------|-----|
| 基础 checkpoint | RCE epoch 5 |
| GRPO epochs | 3 |
| GRPO LR | 5e-6 |
| **KL beta** | **0.12** |
| 冻结 backbone | 是（只训练 50.1% 参数）|
| reward_mode | hard_plus_soft |
| RL 数据 | rl_data_RandSampler_Qwen2_5-VL-3B-Instruct.json |

---

## 训练过程对比

### KL_BETA=0.18 训练指标（本次训练）

| Epoch | Train Loss | Val Loss | PPO Loss | KL | Adv Std | Adv Max | Beta |
|-------|------------|----------|----------|-----|---------|---------|------|
| **1** | ? | ? | ? | ? | ? | ? | 0.18 |
| **2** | ? | ? | ? | ? | ? | ? | 0.18 |
| **3** | ? | ? | ? | ? | ? | ? | 0.18 |

**关键观察**（待填充）：
- KL 值变化趋势
- PPO Loss 变化趋势
- Train Loss 变化趋势
- Advantage 范围

### KL_BETA=0.15 训练指标（参考文档未提供详细指标）

参考文档中未提供详细的训练过程指标，只有最终推理结果。

### KL_BETA=0.12 训练指标（参考）

| Epoch | Train Loss | Val Loss | PPO Loss | KL | Adv Std | Adv Max | Beta |
|-------|------------|----------|----------|-----|---------|---------|------|
| **1** | 0.01162 | 5.11661 | 0.00034 | 0.09400 | 0.0063 | 0.0072 | 0.12 |
| **2** | 0.01059 | 5.11663 | 0.00083 | 0.08131 | 0.0062 | 0.0090 | 0.12 |
| **3** | 0.00982 | 5.11607 | 0.00092 | 0.07414 | 0.0062 | 0.0090 | 0.12 |

---

## GRPO Epoch 1 推理结果对比

### KL_BETA=0.18 推理结果

| 样本数 | Shot 1 | Shot 2 | Shot 3 | Shot 4 |
|--------|--------|--------|--------|--------|
| **100** | ? | ? | ? | ? |
| **200** | ? | ? | ? | ? |
| **400** | ? | ? | ? | ? |
| **800** | ? | ? | ? | ? |

### KL_BETA=0.15 推理结果（参考）

| 样本数 | Shot 1 | Shot 2 | Shot 3 | Shot 4 |
|--------|--------|--------|--------|--------|
| **100** | 63.2% | 65.8% | 60.8% | 61.8% |
| **200** | 58.8% | 56.6% | 53.9% | 55.2% |
| **400** | 53.0% | 51.0% | 50.55% | 50.95% |
| **800** | 49.75% | 47.8% | 47.15% | 47.83% |

### KL_BETA=0.12 推理结果（参考）

| 样本数 | Shot 1 | Shot 2 | Shot 3 | Shot 4 |
|--------|--------|--------|--------|--------|
| **100** | ? | ? | ? | ? |
| **200** | 57.0% | 56.1% | 55.1% | 55.2% |
| **400** | ? | ? | ? | ? |
| **800** | ? | ? | ? | ? |

### Epoch 1 差异对比（200样本）

| Shot | KL_BETA=0.15 | KL_BETA=0.12 | KL_BETA=0.18 | vs 0.15 | vs 0.12 | 评价 |
|------|--------------|--------------|--------------|--------|---------|------|
| **1** | 58.8% | 57.0% | ? | ? | ? | ? |
| **2** | 56.6% | 56.1% | ? | ? | ? | ? |
| **3** | 53.9% | 55.1% | ? | ? | ? | ? |
| **4** | 55.2% | 55.2% | ? | ? | ? | ? |

---

## GRPO Epoch 2 推理结果对比

### KL_BETA=0.18 推理结果

| 样本数 | Shot 1 | Shot 2 | Shot 3 | Shot 4 |
|--------|--------|--------|--------|--------|
| **100** | ? | ? | ? | ? |
| **200** | ? | ? | ? | ? |
| **400** | ? | ? | ? | ? |
| **800** | ? | ? | ? | ? |

### KL_BETA=0.15 推理结果（参考）

| 样本数 | Shot 1 | Shot 2 | Shot 3 | Shot 4 |
|--------|--------|--------|--------|--------|
| **100** | 64.2% | 63.8% | 60.8% | 61.8% |
| **200** | 58.8% | 56.6% | 53.9% | 55.2% |
| **400** | 54.1% | 51.6% | 50.55% | 50.95% |
| **800** | 49.62% | 48.33% | 47.15% | 47.83% |

### KL_BETA=0.12 推理结果（参考）

| 样本数 | Shot 1 | Shot 2 | Shot 3 | Shot 4 |
|--------|--------|--------|--------|--------|
| **100** | ? | ? | ? | ? |
| **200** | ? | ? | ? | ? |
| **400** | ? | ? | ? | ? |
| **800** | ? | ? | ? | ? |

---

## GRPO Epoch 3 推理结果（KL_BETA=0.18 和 0.12 独有）

### KL_BETA=0.18 Epoch 3 推理结果

| 样本数 | Shot 1 | Shot 2 | Shot 3 | Shot 4 |
|--------|--------|--------|--------|--------|
| **100** | ? | ? | ? | ? |
| **200** | ? | ? | ? | ? |
| **400** | ? | ? | ? | ? |
| **800** | ? | ? | ? | ? |

### KL_BETA=0.12 Epoch 3 推理结果（参考）

| 样本数 | Shot 1 | Shot 2 | Shot 3 | Shot 4 |
|--------|--------|--------|--------|--------|
| **100** | ? | ? | ? | ? |
| **200** | ? | ? | ? | ? |
| **400** | ? | ? | ? | ? |
| **800** | ? | ? | ? | ? |

---

## 统计汇总（待填充）

### KL_BETA 对比总结

| KL_BETA | Epoch 1 平均差异 | Epoch 2 平均差异 | 最佳场景 | 评价 |
|---------|-----------------|-----------------|---------|------|
| 0.18 | ? | ? | ? | ? |
| 0.15 | 基准 | 基准 | Shot 1 全场景 | 参考 |
| 0.12 | -0.28% (200样本) | ? | Shot 3 | 略低于基准 |

### 按 Shot 分析（200样本，Epoch 1）

| Shot | KL_BETA=0.15 | KL_BETA=0.12 | KL_BETA=0.18 | 趋势 |
|------|--------------|--------------|--------------|------|
| Shot 1 | 58.8% | 57.0% (-1.8%) | ? | ? |
| Shot 2 | 56.6% | 56.1% (-0.5%) | ? | ? |
| Shot 3 | 53.9% | 55.1% (+1.2%) | ? | ? |
| Shot 4 | 55.2% | 55.2% (0.0%) | ? | ? |

---

## 关键发现（待填充）

### ✅ KL_BETA=0.18 的优势

（待填充）

### ⚠️ KL_BETA=0.18 的劣势

（待填充）

### KL_BETA 选择建议

（待填充）

---

## 使用说明

### 1. 完成 RCE 训练（如果还未完成）

```bash
# 使用 KL_BETA=0.18 训练 RCE + GRPO
bash scripts/train_v3_kl018.sh vqa okvqa_local 0 query_img_text_icd_img_text rand_sampler qwen2.5_vl_3B

# 或从已有的 RCE checkpoint 继续训练 GRPO
bash scripts/train_grpo_kl018_from_rce.sh 5 0 3  # 从 RCE epoch 5 开始，训练 3 个 GRPO epochs
```

### 2. 运行评估

```bash
# 单个评估
bash scripts/eval_grpo_kl018.sh 1 0 100  # epoch 1, GPU 0, 100 样本
bash scripts/eval_grpo_kl018.sh 1 0 200  # epoch 1, GPU 0, 200 样本
bash scripts/eval_grpo_kl018.sh 1 1 400  # epoch 1, GPU 1, 400 样本
bash scripts/eval_grpo_kl018.sh 1 1 800  # epoch 1, GPU 1, 800 样本

# 完整评估（所有 epoch 和样本数）
bash scripts/eval_grpo_kl018_all.sh
```

### 3. 填写对比结果

评估完成后，将推理结果填入上述表格，并更新统计汇总和结论部分。

---

## 预期分析

### KL_BETA 对训练的影响

- **KL_BETA=0.18**（更大）：更强的 KL 约束，策略更新更保守，可能：
  - ✅ 训练更稳定
  - ✅ 避免过度偏离初始策略
  - ⚠️ 可能限制模型学习能力
  - ⚠️ KL 值可能下降较慢

- **KL_BETA=0.12**（更小）：更弱的 KL 约束，策略更新更激进，可能：
  - ✅ 允许更大的策略探索
  - ✅ KL 值下降更快
  - ⚠️ 可能训练不稳定
  - ⚠️ 可能过度偏离初始策略

- **KL_BETA=0.15**（中等）：平衡点，参考配置

### 预期结果

根据 KL_BETA 的影响，预期：
- **KL_BETA=0.18** 可能在 Shot 1 场景表现更好（更保守，更接近初始策略）
- **KL_BETA=0.12** 可能在 Shot 3 场景表现更好（更激进，探索更多）
- **KL_BETA=0.15** 可能是平衡点

