# 0.15 冻结版本 Checkpoint 发现报告

## 找到的 Checkpoint

### Checkpoint 路径

- **.pt 文件**: `results/okvqa/model_cpk/v3_k64_grpo/grpo_epoch1.pt`
- **.ckpt 文件**: `results/okvqa/model_cpk/v3_k64_grpo/grpo_epoch1_v2format.ckpt`
- **文档路径**: `results/okvqa/model_cpk/v3_k64_grpo/grpo_epoch1_v2format.ckpt` ✅ 匹配

### Checkpoint 信息

| 属性 | 值 | 备注 |
|------|-----|------|
| **KL_BETA** | **0.1** | ⚠️ **不是 0.15！** |
| **Epoch** | 0 | GRPO Epoch 1 |
| **Phase** | grpo | GRPO 训练阶段 |

## 关键发现

### 1. KL_BETA 不一致

- **文档中记录**: KL_BETA=0.15
- **Checkpoint 中实际**: KL_BETA=0.1
- **结论**: 文档中的记录可能有误，或者这个 checkpoint 不是文档中提到的那个

### 2. 参数差异很大

| 对比 | 平均参数差异 | 状态 |
|------|-------------|------|
| v3_k64_grpo vs kl012_frozen | **0.041624** | ✅ 差异明显 |
| v3_k64_grpo vs kl015_unfrozen | **0.041622** | ✅ 差异明显 |
| kl012_frozen vs kl015_unfrozen | 0.000288 | ⚠️ 差异很小 |

**结论**: v3_k64_grpo 的 checkpoint 参数差异很大，所以结果不同（56.1%）。

### 3. 投影层参数对比

| 参数 | v3_k64_grpo vs RCE | 状态 |
|------|-------------------|------|
| `input_proj.weight` | 差异很大 | ✅ 被训练了 |
| `query_proj.weight` | 差异很大 | ✅ 被训练了 |
| `cand_proj.weight` | 差异很大 | ✅ 被训练了 |

**结论**: v3_k64_grpo 的 checkpoint 确实训练了投影层，参数变化很大。

## 为什么其他配置结果相同？

### 原因 1: 参数差异太小

- **其他配置**: 参数差异 0.0002-0.0006（平均）
- **v3_k64_grpo**: 参数差异 0.041624（平均）
- **差异倍数**: 约 70-200 倍

### 原因 2: 起点相同

- **其他配置**: 都从 `kl012/rce_epoch5.pt` 开始
- **v3_k64_grpo**: 可能从不同的 RCE checkpoint 开始（需要确认）

### 原因 3: 训练配置不同

- **其他配置**: KL_BETA=0.12-0.18, LR=5e-6-2e-5
- **v3_k64_grpo**: KL_BETA=0.1（可能使用了更大的学习率或更多的 epochs）

## 为什么 v3_k64_grpo 结果不同？

### 可能的原因

1. ✅ **参数差异很大**（0.041624）
   - 投影层参数被显著训练
   - 参数变化足以影响推理结果

2. ✅ **可能使用了不同的 RCE checkpoint**
   - 文档中提到：RCE epoch 2 (val_loss=7.8863)
   - 其他配置使用：RCE epoch 5

3. ✅ **可能训练了更多的 epochs**
   - 文档中提到：GRPO epochs = 3
   - 但实际 checkpoint 是 epoch 1

4. ✅ **可能使用了不同的数据文件**
   - 文档中提到：rl_data_k64_v3.json
   - 其他配置也使用相同的数据文件

5. ✅ **可能使用了不同的训练配置**
   - KL_BETA=0.1（而不是 0.15）
   - 可能使用了更大的学习率

## 结论

1. ✅ **找到了 0.15 冻结版本的 checkpoint**
   - 路径: `v3_k64_grpo/grpo_epoch1.pt`
   - 文档路径匹配 ✅

2. ⚠️ **但 KL_BETA 实际上是 0.1，不是 0.15**
   - 文档中的记录可能有误
   - 或者这个 checkpoint 不是文档中提到的那个

3. ✅ **参数差异很大（0.041624）**
   - 说明这个 checkpoint 确实训练了投影层
   - 参数变化足以影响推理结果

4. ✅ **其他配置参数差异太小（0.0002-0.0006）**
   - 不足以改变模型的输出分布
   - 所以结果相同（55.85%）

## 建议

1. **确认 v3_k64_grpo 的训练配置**
   - 检查训练日志，确认 KL_BETA 和学习率
   - 确认使用的 RCE checkpoint
   - 确认训练 epochs

2. **重新训练 KL_BETA=0.15 的冻结版本**
   - 使用相同的 RCE checkpoint（kl012/rce_epoch5.pt）
   - 使用 KL_BETA=0.15
   - 使用冻结 backbone 配置
   - 对比结果

3. **尝试更大的参数差异**
   - 使用更大的学习率（5e-5 或 1e-4）
   - 使用更多的 epochs（5-10）
   - 使用更小的 KL_BETA（0.05 或 0.08）

