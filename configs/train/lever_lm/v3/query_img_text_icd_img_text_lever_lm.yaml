_target_: lever_lm.models.v3.adapter_builder.build_model_v3_with_adapter

# PointerSelectorV3Config 参数（传递给 build_model_v3 的 config 参数）
config:
  _target_: lever_lm.models.v3.pointer_selector_v3.PointerSelectorV3Config
  d_model: 512 # Changed from 768 to 512 (CLIP base-patch32 outputs 512)
  K: 2         # Changed from 32 to 2 (same as v1/v2)
  shot_num: 2  # Changed from 6 to 2 (same as v1/v2)
  label_smoothing: 0.0
  dropout: 0.5
  hidden_dim: 256
  num_heads: 1
  attn_dropout: 0.1
  num_layers: 3
  # V3 特有参数（离线强化学习）

# 适配器参数
clip_name: openai/clip-vit-base-patch32
query_encoding_flag: ['image', 'text']
icd_encoding_flag: ['image', 'text']
adapter: false
norm: true
cache_dir: null  # CLIP 模型缓存目录（可选），null 时使用默认缓存目录 ~/.cache/huggingface/

# LoRA 配置
use_lora: false  # 是否使用 LoRA 解冻 CLIP
lora_config:  # LoRA 配置参数（仅在 use_lora=true 时生效）
  r: 16  # LoRA rank
  lora_alpha: 32  # LoRA alpha
  target_modules: ['q_proj', 'v_proj', 'k_proj', 'out_proj']  # 目标模块（CLIP 的注意力层）
  lora_dropout: 0.1  # LoRA dropout
  bias: 'none'  # bias 处理方式

