_target_: lever_lm.models.v3.adapter_builder.build_model_v3_with_adapter

# PointerSelectorV3Config 参数（传递给 build_model_v3 的 config 参数）
config:
  _target_: lever_lm.models.v3.pointer_selector_v3.PointerSelectorV3Config
  d_model: 512 # Changed from 768 to 512 (CLIP base-patch32 outputs 512)
  K: 2         # Changed from 32 to 2 (same as v1/v2)
  shot_num: 2  # Changed from 6 to 2 (same as v1/v2)
  label_smoothing: 0.0
  dropout: 0.5
  hidden_dim: 256
  num_heads: 1
  attn_dropout: 0.1
  num_layers: 3
  # V3新增参数（用于GRPO训练，推理时不需要，但保留以兼容）
  clip_epsilon: 0.2
  kl_beta: 0.1
  advantage_clip: 5.0

# 适配器参数
clip_name: openai/clip-vit-base-patch32
query_encoding_flag: ['image', 'text']
icd_encoding_flag: ['image', 'text']
adapter: false
norm: true
