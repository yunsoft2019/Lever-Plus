# Lever-Plus v3 RL ä»£ç ä¸éœ€æ±‚å¯¹æ¯”æŠ¥å‘Š

> å¯¹æ¯”æ—¶é—´ï¼š2025-01-XX  
> å¯¹æ¯”æ–‡ä»¶ï¼š`LeverPlus_v3_RL_plan_cn.md` vs å®é™…ä»£ç å®ç°

---

## âœ… å·²å®Œå…¨ç¬¦åˆéœ€æ±‚çš„éƒ¨åˆ†

### 1. Pointer ç´¢å¼•æ˜ å°„ä¿®å¤ âœ…

**éœ€æ±‚æ–‡æ¡£è¦æ±‚**ï¼ˆç¬¬4.1èŠ‚ï¼‰ï¼š
- å»æ‰ `.get(idx, idx)` fallbackï¼Œæ”¹ä¸ºæ˜¾å¼ `KeyError`

**å®é™…ä»£ç **ï¼ˆ`dataset_v3.py` ç¬¬418-423è¡Œï¼‰ï¼š
```python
mapped_pointer = []
for idx in pointer:
    if idx not in self.cand_idx_to_pos:
        raise KeyError(
            f"[RLBeamDatasetWithEmbedding] Pointer index {idx} not in candidate_indices "
            f"(query_id={query_id})"
        )
    mapped_pointer.append(self.cand_idx_to_pos[idx])
```

**ç»“è®º**ï¼šâœ… **å·²ä¿®å¤**ï¼Œä¸å†ä½¿ç”¨ fallback

---

### 2. Reward è®¡ç®—é€»è¾‘ âœ…

**éœ€æ±‚æ–‡æ¡£è¦æ±‚**ï¼ˆç¬¬2.2èŠ‚ï¼‰ï¼š
- é»˜è®¤ `reward_mode="hard_plus_soft"`ï¼Œ`hard_weight=soft_weight=1.0`
- `alpha=beta=0.0`ï¼Œå› æ­¤ reward = `vqa_correct + vqa_acc_score`ï¼ŒèŒƒå›´ [0, 2]

**å®é™…ä»£ç **ï¼š

1. **`reward_utils.py`**ï¼ˆç¬¬224-275è¡Œï¼‰ï¼š
   - âœ… é»˜è®¤ `reward_mode="hard_plus_soft"`
   - âœ… é»˜è®¤ `hard_weight=1.0`, `soft_weight=1.0`
   - âœ… é»˜è®¤ `alpha=0.0`, `beta=0.0`
   - âœ… `hard_plus_soft` æ¨¡å¼ä¸‹ï¼š`reward = hard_weight * hard + soft_weight * soft`

2. **`dataset_v3.py`**ï¼ˆç¬¬338-455è¡Œï¼‰ï¼š
   - âœ… é»˜è®¤ `reward_mode="hard_plus_soft"`
   - âœ… é»˜è®¤ `reward_alpha=0.0`, `reward_beta=0.0`
   - âœ… é legacy æ¨¡å¼ä¸‹åªä¼ å…¥ correctness ç›¸å…³å‚æ•°ï¼ˆç¬¬444-455è¡Œï¼‰

**ç»“è®º**ï¼šâœ… **å®Œå…¨ç¬¦åˆ**éœ€æ±‚

---

### 3. RL æ•°æ®ç”Ÿæˆ âœ…

**éœ€æ±‚æ–‡æ¡£è¦æ±‚**ï¼ˆç¬¬2.1èŠ‚ï¼‰ï¼š
- ä½¿ç”¨ v2/v3 pointer æ¨¡å‹é‡æ–°åš beam + æ¸©åº¦é‡‡æ · + éšæœºç»„åˆ
- å¯¹æ¯ä¸ª pointer ç”¨ VQA æ¨¡å‹ç”Ÿæˆç­”æ¡ˆå¹¶è®¡ç®— `vqa_correct` ä¸ `vqa_acc_score`
- ä¼˜å…ˆä½¿ç”¨å®˜æ–¹ VQA metricï¼Œfallback åˆ°å­—ç¬¦ä¸²åŒ¹é…

**å®é™…ä»£ç **ï¼ˆ`generate_rl_data.py`ï¼‰ï¼š

1. **Pointer å€™é€‰ç”Ÿæˆ**ï¼ˆç¬¬424-433è¡Œï¼‰ï¼š
   - âœ… ä½¿ç”¨ `generate_pointer_candidates_for_query` åš beam + æ¸©åº¦é‡‡æ · + éšæœºç»„åˆ

2. **Correctness è®¡ç®—**ï¼ˆç¬¬460-523è¡Œï¼‰ï¼š
   - âœ… ä½¿ç”¨ `build_vqa_prompt_and_generate` ç”Ÿæˆç­”æ¡ˆ
   - âœ… ä½¿ç”¨ `compute_vqa_accuracy` è®¡ç®— correctness
   - âœ… ä¼˜å…ˆä½¿ç”¨å®˜æ–¹ VQA metricï¼ˆç¬¬300-330è¡Œï¼‰
   - âœ… Fallback åˆ°å­—ç¬¦ä¸²åŒ¹é…ï¼ˆç¬¬334-349è¡Œï¼‰
   - âœ… ç»Ÿè®¡æ–‡ä»¶æ–¹å¼ vs fallback çš„ä½¿ç”¨æƒ…å†µï¼ˆç¬¬402-550è¡Œï¼‰

**ç»“è®º**ï¼šâœ… **å®Œå…¨ç¬¦åˆ**éœ€æ±‚

---

### 4. æ•°æ®é›†å®ç° âœ…

**éœ€æ±‚æ–‡æ¡£è¦æ±‚**ï¼ˆç¬¬2.3èŠ‚ï¼‰ï¼š
- ä» RL JSON ä¸­è¯»å– `pointer_candidates`
- é€šè¿‡ `compute_reward_for_candidate` è®¡ç®—æ¯ä¸ª pointer çš„ reward
- ç»„å†…åš Z-score å½’ä¸€åŒ–
- ä¿ç•™åŸå§‹ reward ä¾› RCE ä½¿ç”¨

**å®é™…ä»£ç **ï¼ˆ`dataset_v3.py` ç¬¬318-548è¡Œï¼‰ï¼š

1. **æ•°æ®è¯»å–**ï¼ˆç¬¬392-401è¡Œï¼‰ï¼š
   - âœ… ä» `rl_data` ä¸­è¯»å– `pointer_candidates`

2. **Reward è®¡ç®—**ï¼ˆç¬¬427-456è¡Œï¼‰ï¼š
   - âœ… ä½¿ç”¨ `compute_reward_for_candidate` è®¡ç®— reward

3. **å½’ä¸€åŒ–**ï¼ˆç¬¬528-533è¡Œï¼‰ï¼š
   - âœ… ç»„å†… Z-score å½’ä¸€åŒ–ï¼š`(beam_rewards_raw - mean) / std`

4. **åŸå§‹ reward**ï¼ˆç¬¬541è¡Œï¼‰ï¼š
   - âœ… ä¿ç•™ `beam_rewards_raw` ä¾› RCE ä½¿ç”¨

**ç»“è®º**ï¼šâœ… **å®Œå…¨ç¬¦åˆ**éœ€æ±‚

---

## âœ… å·²ä¿®å¤çš„ä¸ä¸€è‡´éƒ¨åˆ†

### 1. è®­ç»ƒè„šæœ¬é»˜è®¤ reward_mode âœ…ï¼ˆå·²ä¿®å¤ï¼‰

**éœ€æ±‚æ–‡æ¡£è¦æ±‚**ï¼ˆç¬¬14è¡Œï¼‰ï¼š
```text
é»˜è®¤ `reward_mode="hard_plus_soft"`ï¼Œ`hard_weight=soft_weight=1.0`ï¼Œ`alpha=beta=0.0`
```

**ä¿®å¤å‰**ï¼ˆ`grpo_post_train.py` ç¬¬439è¡Œï¼‰ï¼š
```python
parser.add_argument("--reward_mode", type=str, default="separated", ...)
```

**ä¿®å¤å**ï¼ˆ`grpo_post_train.py` ç¬¬439è¡Œï¼‰ï¼š
```python
parser.add_argument("--reward_mode", type=str, default="hard_plus_soft", ...)
```

**ä¿®å¤è¯´æ˜**ï¼š
- âœ… å·²å°†è®­ç»ƒè„šæœ¬çš„é»˜è®¤å€¼æ”¹ä¸º `"hard_plus_soft"`ï¼Œä¸éœ€æ±‚æ–‡æ¡£å®Œå…¨ä¸€è‡´
- âœ… æ›´æ–°äº† help æ–‡æœ¬ï¼Œæ˜ç¡®è¯´æ˜é»˜è®¤æ¨¡å¼åŠå…¶ reward èŒƒå›´

---

## ğŸ“Š æ€»ä½“è¯„ä¼°

### ç¬¦åˆåº¦ï¼š100% âœ…

**å·²å®ç°**ï¼š
- âœ… Pointer ç´¢å¼•æ˜ å°„ä¿®å¤ï¼ˆå·²ä¿®å¤ fallback é—®é¢˜ï¼‰
- âœ… Reward è®¡ç®—é€»è¾‘ï¼ˆå®Œå…¨ç¬¦åˆéœ€æ±‚ï¼‰
- âœ… RL æ•°æ®ç”Ÿæˆï¼ˆå®Œå…¨ç¬¦åˆéœ€æ±‚ï¼‰
- âœ… æ•°æ®é›†å®ç°ï¼ˆå®Œå…¨ç¬¦åˆéœ€æ±‚ï¼‰
- âœ… è®­ç»ƒè„šæœ¬é»˜è®¤ `reward_mode`ï¼ˆå·²ä¿®å¤ä¸º `hard_plus_soft`ï¼‰

---

## ğŸ”§ å·²å®Œæˆçš„ä¿®æ”¹

### ä¿®æ”¹ 1ï¼šç»Ÿä¸€ reward_mode é»˜è®¤å€¼ âœ…

**æ–‡ä»¶**ï¼š`lever_lm/workflows/grpo_post_train.py`

**ä¿®æ”¹ä½ç½®**ï¼šç¬¬439è¡Œ

**ä¿®æ”¹å‰**ï¼š
```python
parser.add_argument("--reward_mode", type=str, default="separated", ...)
```

**ä¿®æ”¹å**ï¼š
```python
parser.add_argument("--reward_mode", type=str, default="hard_plus_soft", ...)
```

**çŠ¶æ€**ï¼šâœ… **å·²å®Œæˆ**

---

## âœ… æ€»ç»“

ä»£ç å®ç°**å®Œå…¨ç¬¦åˆ**éœ€æ±‚æ–‡æ¡£çš„æ‰€æœ‰è¦æ±‚ï¼âœ…

æ‰€æœ‰å…³é”®è¦æ±‚éƒ½å·²æ­£ç¡®å®ç°ï¼š
- âœ… Pointer æ˜ å°„å·²ä¿®å¤ï¼ˆæ˜¾å¼æŠ¥é”™ï¼Œä¸ä½¿ç”¨ fallbackï¼‰
- âœ… Reward è®¡ç®—é€»è¾‘æ­£ç¡®ï¼ˆhard+softï¼Œalpha=beta=0ï¼Œé»˜è®¤ `hard_plus_soft`ï¼‰
- âœ… RL æ•°æ®ç”Ÿæˆå®Œæ•´ï¼ˆbeam+é‡‡æ ·+correctnessï¼Œä¼˜å…ˆä½¿ç”¨å®˜æ–¹ VQA metricï¼‰
- âœ… æ•°æ®é›†å®ç°æ­£ç¡®ï¼ˆZ-score å½’ä¸€åŒ–ï¼Œä¿ç•™åŸå§‹ rewardï¼‰
- âœ… è®­ç»ƒè„šæœ¬é»˜è®¤å€¼æ­£ç¡®ï¼ˆ`reward_mode="hard_plus_soft"`ï¼‰

**ä»£ç ä¸éœ€æ±‚æ–‡æ¡£å·²å®Œå…¨ä¸€è‡´ï¼** ğŸ‰

