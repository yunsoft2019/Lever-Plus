# KL_BETA 0.12 vs 0.15 训练曲线分析报告

## 实验设置

- **KL_BETA=0.12**: 50 个 epoch
- **KL_BETA=0.15**: 50 个 epoch
- **训练数据**: OKVQA 数据集

## 训练指标对比

### 1. KL散度 (KL Divergence)

| 指标 | KL_BETA=0.12 | KL_BETA=0.15 | 差异 |
|------|--------------|--------------|------|
| 平均 | 0.059986 | 0.059548 | 0.000438 |
| 初始 | 0.079385 | 0.078858 | 0.000527 |
| 最终 | 0.053792 | 0.053616 | 0.000176 |
| 变化 | -32.24% | -32.01% | -0.23% |

**分析**:
- KL散度差异非常小（平均差异仅 0.000438）
- 两个模型的KL散度变化趋势几乎相同（都下降了约32%）
- **结论**: 两个模型学到了**非常相似的策略**

### 2. KL Loss

| 指标 | KL_BETA=0.12 | KL_BETA=0.15 | 差异 |
|------|--------------|--------------|------|
| 平均 | 0.00719828 | 0.00893216 | -0.00173389 |
| 初始 | 0.00952625 | 0.01182874 | -0.00230249 |
| 最终 | 0.00645507 | 0.00804239 | -0.00158732 |

**分析**:
- KL_BETA=0.12 的 KL Loss **更低**（平均低 0.0017）
- 这符合预期：KL_BETA 越小，KL Loss 的权重越小，因此 KL Loss 值更小
- **结论**: KL_BETA 的设置确实影响了 KL Loss，但差异不大

### 3. PPO Loss

| 指标 | KL_BETA=0.12 | KL_BETA=0.15 | 差异 |
|------|--------------|--------------|------|
| 平均 | 0.00956868 | 0.00900020 | 0.00056848 |
| 初始 | 0.00818351 | 0.00704511 | 0.00113840 |
| 最终 | 0.00805887 | 0.00551664 | 0.00254224 |

**分析**:
- KL_BETA=0.15 的 PPO Loss **更低**（平均低 0.0006，最终低 0.0025）
- 这可能是因为更高的 KL_BETA 提供了更强的正则化，使策略更新更稳定
- **结论**: KL_BETA=0.15 的策略更新更稳定

### 4. GRPO Loss

| 指标 | KL_BETA=0.12 | KL_BETA=0.15 | 差异 |
|------|--------------|--------------|------|
| 平均 | 0.01676696 | 0.01793236 | -0.00116540 |
| 初始 | 0.01770976 | 0.01887384 | -0.00116408 |
| 最终 | 0.01451395 | 0.01355903 | 0.00095492 |

**分析**:
- 平均 GRPO Loss 差异很小（-0.0012）
- 最终 GRPO Loss 几乎相同（差异仅 0.0010）
- **结论**: 两个模型的总损失非常接近

### 5. Validation Loss

| 指标 | KL_BETA=0.12 | KL_BETA=0.15 | 差异 |
|------|--------------|--------------|------|
| 平均 | 8.009721 | 8.003451 | 0.006270 |
| 初始 | 8.057354 | 8.063024 | -0.005670 |
| 最终 | 7.987274 | 7.982051 | 0.005223 |
| 最小 | 7.972695 (Epoch 47) | 7.977539 (Epoch 41) | -0.004844 |

**分析**:
- Validation Loss 差异非常小（平均差异仅 0.006）
- KL_BETA=0.15 的最终 Validation Loss **略低**（7.982 vs 7.987）
- KL_BETA=0.15 在更早的 epoch（41）达到最小 Validation Loss
- **结论**: 两个模型的性能**几乎相同**，KL_BETA=0.15 略好但差异很小

### 6. Mean Ratio (Policy Update Ratio)

| 指标 | KL_BETA=0.12 | KL_BETA=0.15 | 差异 |
|------|--------------|--------------|------|
| 平均 | 0.903376 | 0.906400 | -0.003024 |
| 初始 | 0.838018 | 0.821189 | 0.016829 |
| 最终 | 0.916408 | 0.916881 | -0.000473 |

**分析**:
- Mean Ratio 差异非常小（平均差异仅 0.003）
- 最终 Mean Ratio 几乎相同（0.9164 vs 0.9169）
- **结论**: 两个模型的策略更新比例**几乎相同**

### 7. Mean Advantage

| 指标 | KL_BETA=0.12 | KL_BETA=0.15 | 差异 |
|------|--------------|--------------|------|
| 平均 | -0.00000009 | -0.00000009 | 0.00000000 |
| 初始 | -0.00000009 | -0.00000009 | 0.00000000 |
| 最终 | -0.00000009 | -0.00000009 | 0.00000000 |

**分析**:
- Mean Advantage **完全相同**（都是 -0.00000009）
- **结论**: 两个模型的优势估计**完全相同**

## 关键发现

### 1. 两个模型学到了**非常相似的策略**

- KL散度差异极小（0.000438）
- Mean Ratio 几乎相同（0.9164 vs 0.9169）
- Mean Advantage 完全相同

### 2. KL_BETA 的影响主要体现在 KL Loss 上

- KL_BETA=0.12 的 KL Loss 更低（符合预期）
- 但 KL散度（实际策略差异）几乎相同

### 3. 性能差异很小

- Validation Loss 差异仅 0.006（约 0.075%）
- 最终性能几乎相同

### 4. 收敛性

- KL_BETA=0.15 的收敛更稳定（KL散度变化趋势更小）
- 两个模型都已收敛到相似的状态

## 结论

1. **两个模型学到了几乎相同的策略**
   - KL散度、Mean Ratio、Mean Advantage 都几乎相同
   - 这解释了为什么推理时选择的范例索引 100% 相同

2. **KL_BETA 差异（0.12 vs 0.15）的影响很小**
   - 主要体现在 KL Loss 的数值上
   - 但对最终策略的影响很小

3. **权重差异不足以改变离散选择**
   - 虽然权重有差异（50.15% 的参数不同）
   - 但策略几乎相同，导致范例选择 100% 相同
   - 因此推理准确率也完全相同

4. **建议**
   - 如果需要观察到明显的差异，需要：
     - 使用更大的 KL_BETA 差异（例如 0.1 vs 0.2）
     - 或者使用相同的 epoch 进行对比
     - 或者检查更细粒度的指标（例如不同样本的范例选择分布）

## 文件位置

- **训练指标 (KL_BETA=0.12)**: `results/okvqa/training_metrics_kl012.json`
- **训练指标 (KL_BETA=0.15)**: `results/okvqa/training_metrics_kl015.json`
- **分析脚本**: `scripts/analyze_training_curves.py`

## 日期

2025-12-22




