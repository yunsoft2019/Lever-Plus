# 新强化学习方案结果对比

## 实验配置

- **数据集**: OKVQA
- **推理模型**: Qwen2.5-VL-3B-Instruct
- **采样器**: RandSampler
- **RCE-only baseline (v3_rce_only)**: reward = hard + soft = vqa_correct + vqa_acc_score（范围 [0, 2]），**仅RCE训练（5 epochs），无GRPO**

---

## 100条数据对比

| Shot Num | v2 | v3_rce_only (旧, 2025-12-10) | v3_rce_only (新, 2025-12-11) | 新 vs v2 | 新 vs 旧 |
|----------|-----|------------------------------|------------------------------|----------|----------|
| **1** | 63.8% | **64.2%** | 63.8% | 0.0% | -0.4% |
| **2** | 63.8% | **64.8%** | **64.8%** | **+1.0%** | 0.0% |
| **3** | **62.8%** | 62.8% | 62.8% | 0.0% | 0.0% |
| **4** | **61.4%** | 61.4% | 61.4% | 0.0% | 0.0% |

**100条数据结论**：
- shot_num=1: 新结果（63.8%）与 v2 持平，但低于旧结果（64.2%，-0.4%）
- shot_num=2: 新旧结果一致（64.8%），**均优于 v2（+1.0%）**
- shot_num=3,4: 新旧结果一致，与 v2 持平

---

## 200条数据对比

| Shot Num | v2 | v3_rce_only (旧, 2025-12-10) | v3_rce_only (新, 2025-12-11) | 新 vs v2 | 新 vs 旧 |
|----------|-----|------------------------------|------------------------------|----------|----------|
| **1** | 56.7% | **57.0%** | **57.3%** | **+0.6%** | **+0.3%** |
| **2** | 56.1% | **56.6%** | **56.6%** | **+0.5%** | 0.0% |
| **3** | **55.5%** | 55.4% | 54.9% | -0.6% | -0.5% |
| **4** | **54.7%** | 54.5% | 54.7% | 0.0% | **+0.2%** |

**200条数据结论**：
- **新结果表现更优**：
  - shot_num=1: 新结果（57.3%）**优于旧结果（57.0%，+0.3%）**，**优于 v2（+0.6%）**
  - shot_num=2: 新旧结果一致（56.6%），**均优于 v2（+0.5%）**
  - shot_num=3: 新结果（54.9%）略低于旧结果（55.4%，-0.5%），也低于 v2（-0.6%）
  - shot_num=4: 新结果（54.7%）**优于旧结果（54.5%，+0.2%）**，与 v2 持平
- **关键发现**：新结果在 shot_num=1,4 时表现更好，但在 shot_num=3 时略差

---

## 400条数据对比

| Shot Num | v2 | v3_rce_only (旧, 2025-12-10) | v3_rce_only (新, 2025-12-11) | 新 vs v2 | 新 vs 旧 |
|----------|-----|------------------------------|------------------------------|----------|----------|
| **1** | 53.1% | 52.55% | 52.55% | -0.55% | 0.0% |
| **2** | 51.3% | **51.65%** | 51.55% | **+0.25%** | -0.1% |
| **3** | **51.75%** | 51.05% | 50.8% | -0.95% | -0.25% |
| **4** | **50.35%** | 49.6% | 49.95% | -0.4% | **+0.35%** |

**400条数据结论**：
- shot_num=1: 新旧结果一致（52.55%），略低于 v2（-0.55%）
- shot_num=2: 新结果（51.55%）略低于旧结果（51.65%，-0.1%），但仍**优于 v2（+0.25%）**
- shot_num=3: 新结果（50.8%）略低于旧结果（51.05%，-0.25%），也低于 v2（-0.95%）
- shot_num=4: 新结果（49.95%）**优于旧结果（49.6%，+0.35%）**，但仍低于 v2（-0.4%）

---

## 800条数据对比

| Shot Num | v0 | v1 | v2 | v3_rce_only (旧, 2025-12-10) | v3_rce_only (新, 2025-12-11) | 新 vs v0 | 新 vs v1 | 新 vs v2 | 新 vs 旧 |
|----------|-----|-----|-----|------------------------------|------------------------------|----------|----------|----------|----------|
| **1** | **50.95%** | 50.7% | 49.0% | 48.73% | 48.7% | -2.25% | -2.0% | -0.3% | -0.03% |
| **2** | 47.08% | 47.33% | 48.08% | **48.35%** | **48.12%** | **+1.04%** | **+0.79%** | **+0.04%** | -0.23% |
| **3** | 44.95% | 46.35% | **48.33%** | 47.8% | 47.8% | +2.85% | +1.45% | -0.53% | 0.0% |
| **4** | 43.77% | 47.4% | **47.62%** | 47.17% | 47.33% | +3.56% | -0.07% | -0.29% | **+0.16%** |

**800条数据结论**：
- shot_num=1: 新旧结果接近（48.7% vs 48.73%），均低于所有版本（v0 50.95% > v1 50.7% > RCE-only > v2 49.0%）
- shot_num=2: 新结果（48.12%）略低于旧结果（48.35%，-0.23%），但仍**优于 v2（+0.04%）**，**优于 v0（+1.04%）**，**优于 v1（+0.79%）**
- shot_num=3: 新旧结果一致（47.8%），略低于 v2（-0.53%），但优于 v0（+2.85%）和 v1（+1.45%）
- shot_num=4: 新结果（47.33%）**优于旧结果（47.17%，+0.16%）**，但仍略低于 v2（-0.29%），优于 v0（+3.56%）

---

## 总体结论

### RCE-only baseline (v3_rce_only) vs v0/v1/v2

| 指标 | 旧结果（2025-12-10） | 新结果（2025-12-11） | 新 vs 旧 |
|------|---------------------|---------------------|----------|
| shot_num=1 | 64.2%（100条），优于 v2（+0.4%）；57.0%（200条），优于 v2（+0.3%）；52.55%（400条），略低于 v2（-0.55%）；48.73%（800条），低于 v0/v1/v2 | 63.8%（100条），与 v2 持平；**57.3%**（200条），**优于 v2（+0.6%）**；52.55%（400条），略低于 v2（-0.55%）；48.7%（800条），低于 v0/v1/v2 | 100条：-0.4%；200条：**+0.3%**；400条：0.0%；800条：-0.03% |
| shot_num=2 | **64.8%**（100条），**优于 v2（+1.0%）**；**56.6%**（200条），**优于 v2（+0.5%）**；**51.65%**（400条），**优于 v2（+0.35%）**；**48.35%**（800条），**优于 v2（+0.27%）** | **64.8%**（100条），**优于 v2（+1.0%）**；**56.6%**（200条），**优于 v2（+0.5%）**；**51.55%**（400条），**优于 v2（+0.25%）**；**48.12%**（800条），**优于 v2（+0.04%）** | 100条：0.0%；200条：0.0%；400条：-0.1%；800条：-0.23% |
| shot_num=3 | 62.8%（100条），与 v2 持平；55.4%（200条），接近 v2（-0.1%）；51.05%（400条），略低于 v2（-0.7%）；47.8%（800条），略低于 v2（-0.53%） | 62.8%（100条），与 v2 持平；54.9%（200条），略低于 v2（-0.6%）；50.8%（400条），略低于 v2（-0.95%）；47.8%（800条），略低于 v2（-0.53%） | 100条：0.0%；200条：-0.5%；400条：-0.25%；800条：0.0% |
| shot_num=4 | 61.4%（100条），与 v2 持平；54.5%（200条），接近 v2（-0.2%）；49.6%（400条），略低于 v2（-0.75%）；47.17%（800条），略低于 v2（-0.45%） | 61.4%（100条），与 v2 持平；54.7%（200条），与 v2 持平；49.95%（400条），略低于 v2（-0.4%）；47.33%（800条），略低于 v2（-0.29%） | 100条：0.0%；200条：**+0.2%**；400条：**+0.35%**；800条：**+0.16%** |

### 关键发现

1. **新旧结果对比分析**：
   - **shot_num=1**: 新结果在 200 条数据上表现更好（57.3% vs 57.0%，+0.3%），但在 100 条数据上略差（63.8% vs 64.2%，-0.4%）
   - **shot_num=2**: 新旧结果基本一致，在所有数据规模上都稳定优于 v2
   - **shot_num=3**: 新结果在部分数据规模上略差（200条：-0.5%，400条：-0.25%）
   - **shot_num=4**: 新结果在多个数据规模上表现更好（200条：+0.2%，400条：+0.35%，800条：+0.16%）

2. **RCE-only baseline 在 shot_num=2 时表现最佳**
   - 新旧结果在所有数据规模（100/200/400/800条）上都**稳定优于 v2**
   - 新结果提升幅度：+1.0%（100条）、+0.5%（200条）、+0.25%（400条）、+0.04%（800条）
   - **在 800 条数据上，新结果同时优于 v0、v1、v2**

3. **RCE-only baseline 在 shot_num=1 时表现良好**
   - 新结果在 100 条数据上与 v2 持平（63.8%），但低于旧结果（64.2%）
   - 新结果在 200 条数据上优于 v2（+0.6%），也优于旧结果（+0.3%）
   - 在 400 条和 800 条数据上略低于 v2（-0.55% 和 -0.3%）
   - 在 800 条数据上，v0 表现最好（50.95%），新结果为 48.7%

3. **RCE-only baseline 在 shot_num≥3 时与 v2 接近**
   - 差异在 -0.75% 以内
   - 在 800 条数据上，shot_num=3 时 RCE-only（47.8%）优于 v0（+2.85%）和 v1（+1.45%）
   - 表现稳定，没有明显退化

4. **数据规模趋势**
   - 随着数据规模增加（100→200→400→800），RCE-only 相对于 v2 的优势在 shot_num=2 时保持稳定
   - 在 shot_num=1 时，小数据规模（100/200条）上 RCE-only 优于 v2，大数据规模（400/800条）上略低于 v2
   - 在 shot_num≥3 时，RCE-only 与 v2 的差距随数据规模增加而略有扩大

### 建议

1. **✅ 推荐使用 RCE-only baseline**：
   - 训练配置：`--rce_epochs 5 --grpo_epochs 0`
   - Reward：`hard_plus_soft`（默认）
   - **在 shot_num=2 时稳定优于 v2**

2. **🔬 后续探索方向**：
   - 探索不同的 reward_mode（separated、hard_plus_soft_v2 等）
   - 对比 RCE-only 在不同 reward_mode 下的表现
   - 优化 RCE 训练参数（epochs、learning rate 等）

---

## 更新记录

- **2025-12-11**: 新增最新推理结果（100/200/400/800条数据），保留旧结果进行对比
  - 训练配置：RCE Epochs=5, GRPO Epochs=0, Reward Mode=hard_plus_soft
  - 关键发现：
    - 新旧结果在 shot_num=2 时基本一致，均稳定优于 v2
    - 新结果在 shot_num=1 的 200 条数据上表现更好（57.3% vs 57.0%，+0.3%）
    - 新结果在 shot_num=4 的多个数据规模上表现更好（200条：+0.2%，400条：+0.35%，800条：+0.16%）
    - 新结果在 shot_num=3 的部分数据规模上略差（200条：-0.5%，400条：-0.25%）
- **2025-12-10**: 新增 RCE-only baseline 结果（100/200/400/800条数据）
  - 训练配置：RCE Epochs=5, GRPO Epochs=0, Reward Mode=hard_plus_soft
  - 关键发现：
    - RCE-only 在 shot_num=2 时稳定优于 v2
    - 在 800 条数据上，RCE-only 在 shot_num=2 时同时优于 v0、v1、v2
    - 添加了 v0、v1、v2 的完整对比（800条数据）
