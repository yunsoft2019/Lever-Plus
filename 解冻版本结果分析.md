# 解冻版本结果分析

## 结果对比

| 配置 | Shot 1 | Shot 2 | Shot 3 | Shot 4 | 平均 | vs 冻结0.15 |
|------|--------|--------|--------|--------|------|-------------|
| **解冻版本（0.15，Epoch 3）** | 57.0% | 56.1% | 55.1% | 55.2% | **55.85%** | -0.25% ⬇️ |
| **冻结版本（0.15，Epoch 1）** | 58.8% | 56.6% | 53.9% | 55.2% | **56.1%** | 基准 ✅ |
| **冻结版本（0.12/0.145/0.155/0.18，Epoch 1）** | 57.0% | 56.1% | 55.1% | 55.2% | **55.85%** | -0.25% ⬇️ |

## 关键发现

### 1. 解冻版本的结果和冻结版本（0.12/0.145/0.155/0.18）完全相同

**完全相同的结果**：
- Shot 1: 57.0%
- Shot 2: 56.1%
- Shot 3: 55.1%
- Shot 4: 55.2%
- 平均: 55.85%

这说明解冻版本虽然训练了所有参数，但最终效果和只训练 pointer head 的版本（0.12/0.145/0.155/0.18）完全相同。

### 2. 解冻版本比冻结版本（0.15）更差

- 解冻版本: 55.85%
- 冻结版本（0.15）: 56.1%
- 差异: -0.25%

这说明解冻版本**没有带来性能提升**，反而**降低了性能**。

## 参数变化分析

### 投影层参数变化

| 参数 | RCE mean | 解冻 mean | 平均差异 | 最大差异 | 相对变化 |
|------|----------|-----------|----------|----------|----------|
| `input_proj.weight` | -0.000059 | -0.000059 | 0.000274 | 0.001799 | 0.03% |
| `query_proj.weight` | 0.003981 | 0.003978 | 0.000269 | 0.001704 | 0.01% |
| `cand_proj.weight` | 0.003918 | 0.003913 | 0.000302 | 0.001680 | 0.02% |

**观察**：
- ⚠️ **投影层参数变化非常小**（平均差异只有 0.0002-0.0003）
- ⚠️ **相对变化只有 0.01-0.03%**，几乎可以忽略不计
- ⚠️ **参数几乎没有真正被训练**

### Cross-Attention 参数变化

| 参数 | 平均差异 |
|------|----------|
| `cross_attn_layers.0.in_proj_weight` | 0.000358 |
| `cross_attn_layers.0.in_proj_bias` | 0.000312 |
| `cross_attn_layers.0.out_proj.weight` | 0.000334 |
| `cross_attn_layers.0.out_proj.bias` | 0.000358 |

**观察**：
- ⚠️ **Cross-attention 参数变化也很小**（平均差异 0.0003-0.0004）
- ⚠️ **所有参数的变化都很小**，说明训练过程非常保守

## 可能的原因

### 1. 学习率太小

- **当前学习率**: 5e-6
- **问题**: 学习率太小，导致投影层参数几乎没有更新
- **证据**: 投影层参数变化只有 0.01-0.03%

### 2. KL_BETA 约束太强

- **当前 KL_BETA**: 0.15
- **问题**: KL 约束太强，限制了策略更新幅度
- **证据**: 所有参数的变化都很小

### 3. 训练不充分

- **当前 epochs**: 3
- **问题**: 虽然训练了 3 个 epochs，但参数变化很小
- **可能**: 投影层参数在早期就被"锁定"了

### 4. 破坏了 RCE 表示

- **问题**: 虽然投影层参数变化很小，但可能已经破坏了 RCE 阶段学到的良好表示
- **证据**: 解冻版本的结果（55.85%）比冻结版本（0.15）更差（56.1%）

## 结论

### ✅ 解冻版本确实训练了所有参数

- Checkpoint 中包含了投影层参数（`input_proj`, `query_proj`, `cand_proj`）
- 参数确实有变化（虽然很小）

### ❌ 但训练效果不好

- 投影层参数变化非常小（0.01-0.03%）
- 最终结果和只训练 pointer head 的版本完全相同
- 比冻结版本（0.15）更差

### ⚠️ 可能的原因

1. **学习率太小**：5e-6 可能不足以更新投影层参数
2. **KL_BETA 约束太强**：限制了策略更新幅度
3. **训练不充分**：虽然训练了 3 个 epochs，但参数变化很小
4. **破坏了 RCE 表示**：即使变化很小，也可能破坏了 RCE 阶段学到的良好表示

## 建议

### 1. 尝试更大的学习率

```bash
# 使用更大的学习率（如 1e-5 或 2e-5）
GRPO_LR=1e-5 bash scripts/train_grpo_kl015_unfrozen_from_rce.sh 5 0 3 kl012
```

### 2. 尝试更小的 KL_BETA

```bash
# 使用更小的 KL_BETA（如 0.1），允许更大的策略更新
KL_BETA=0.1 bash scripts/train_grpo_kl015_unfrozen_from_rce.sh 5 0 3 kl012
```

### 3. 只训练 1-2 个 epochs

```bash
# 只训练 1-2 个 epochs，避免过拟合
bash scripts/train_grpo_kl015_unfrozen_from_rce.sh 5 0 1 kl012
```

### 4. 保持冻结版本

**当前最佳配置**：
- **冻结版本（KL_BETA=0.15，Epoch 1）**: 56.1%
- **解冻版本（KL_BETA=0.15，Epoch 3）**: 55.85%

**建议**：继续使用冻结版本，因为：
- ✅ 性能更好（56.1% vs 55.85%）
- ✅ 训练更快（只训练 50.1% 参数）
- ✅ 更稳定（保护 RCE 阶段学到的表示）

## 下一步

1. ⏳ **待完成**: 检查训练日志，看训练指标是否正常
2. ⏳ **待完成**: 对比 Epoch 1 和 Epoch 3 的结果，看是否有过拟合
3. ⏳ **可选**: 尝试更大的学习率或更小的 KL_BETA
4. ✅ **建议**: 保持冻结版本（KL_BETA=0.15）

